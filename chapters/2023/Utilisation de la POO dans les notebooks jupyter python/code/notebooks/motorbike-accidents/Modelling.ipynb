{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    ")\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'datasets'\n",
    "FIGURES_PATH = 'figures'\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('muted')\n",
    "sns.palplot(sns.color_palette())\n",
    "\n",
    "season_order = ['winter', 'spring', 'summer', 'autumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorbike_data = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(DATASET_PATH, 'cleanted_motorbike_ambulance_calls.csv'),\n",
    "        parse_dates=['date'],\n",
    "        dayfirst=False,\n",
    "    )\n",
    "    .assign(\n",
    "        yr=lambda x: np.where(\n",
    "            x['yr'] == 2011,\n",
    "            0,\n",
    "            1\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        season=lambda x: (\n",
    "            pd.Categorical(\n",
    "                x['season'], \n",
    "                categories=season_order, \n",
    "                ordered=True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .drop(columns='was_missing')\n",
    ")\n",
    "motorbike_data.info()\n",
    "motorbike_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = motorbike_data.drop(columns='cnt'), motorbike_data['cnt']\n",
    "\n",
    "# No time machine: use 'past' data for training, use 'future' data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "assert X_train.index.max() < X_test.index.min()\n",
    "\n",
    "print('Train: ', X_train[['date', 'hr']].nlargest(1, columns=['date', 'hr']))\n",
    "print('Test: ', X_test[['date', 'hr']].nsmallest(1, columns=['date', 'hr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMeanStdTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, feature, lags=None):\n",
    "        self.feature = feature\n",
    "        self.feature_mean_and_std = None\n",
    "        self.lags = lags\n",
    "        \n",
    "    def _get_lags(self):\n",
    "        return sorted(self.lags) if self.lags else [0]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_mean_and_std = (\n",
    "            X[['hr', self.feature]]\n",
    "            .groupby('hr')\n",
    "            [self.feature]\n",
    "            .agg(['mean', 'std'])\n",
    "            .rename(columns={\n",
    "                'mean': f'{self.feature}_mean', \n",
    "                'std': f'{self.feature}_std'\n",
    "            })\n",
    "        )    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.feature_mean_and_std is None:\n",
    "            raise RuntimeError('Need to fit() first!')\n",
    "        \n",
    "        data_with_feature = (\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                self.feature_mean_and_std,\n",
    "                how='left',\n",
    "                left_on='hr',\n",
    "                right_index=True\n",
    "            )\n",
    "            .sort_values(['date', 'hr'])\n",
    "        )\n",
    "        \n",
    "        for lag in self._get_lags():\n",
    "            if lag == 0:\n",
    "                continue\n",
    "            data_with_feature = (\n",
    "                data_with_feature\n",
    "                .assign(**{\n",
    "                    f'{self.feature}_mean_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}_mean']\n",
    "                        .shift(\n",
    "                            lag, \n",
    "                            fill_value=x.iloc[:lag][f'{self.feature}_mean'].mean()\n",
    "                        )\n",
    "                    ),\n",
    "                    f'{self.feature}_std_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}_std']\n",
    "                        .shift(\n",
    "                            lag, \n",
    "                            fill_value=x.iloc[:lag][f'{self.feature}_std'].mean()\n",
    "                        )\n",
    "                    )\n",
    "                })\n",
    "            )\n",
    "            \n",
    "        if 0 not in self._get_lags():\n",
    "            data_with_feature = (\n",
    "                data_with_feature\n",
    "                .drop(columns=[f'{self.feature}_mean', f'{self.feature}_std'])\n",
    "            )\n",
    "        \n",
    "        return (\n",
    "            # We sorted, so we have to restore the original ordering\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                data_with_feature,\n",
    "                how='left',\n",
    "                on=['date', 'hr']\n",
    "            )\n",
    "            .drop(columns=['date', 'hr'])\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = []\n",
    "        for lag in self._get_lags():\n",
    "            if lag == 0:\n",
    "                feature_names.extend([\n",
    "                    f'{self.feature}_mean', \n",
    "                    f'{self.feature}_std'\n",
    "                ])\n",
    "            else:\n",
    "                feature_names.extend([\n",
    "                    f'{self.feature}_mean_{lag}h_lag', \n",
    "                    f'{self.feature}_std_{lag}h_lag'\n",
    "                ])\n",
    "        return feature_names\n",
    "    \n",
    "(\n",
    "    FeatureMeanStdTransformer('hum', lags=[1, 2, 3, 0])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CntMeanStdTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, lags=None):\n",
    "        self.lags = lags\n",
    "        self.feature_transformer = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise RuntimeError('Target variable is required for fitting!')\n",
    "            \n",
    "        self.feature_transformer = FeatureMeanStdTransformer('cnt', self.lags)    \n",
    "        \n",
    "        data = (\n",
    "            pd.concat(\n",
    "                [X['hr'], y],\n",
    "                axis='columns',\n",
    "                sort=False\n",
    "            )\n",
    "        )\n",
    "        self.feature_transformer.fit(data)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.feature_transformer is None:\n",
    "            raise RuntimeError('Need to fit() first!')\n",
    "        return self.feature_transformer.transform(X)\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        if self.feature_transformer is None:\n",
    "            raise RuntimeError('Need to fit() first!')\n",
    "        return self.feature_transformer.get_feature_names(in_names)\n",
    "    \n",
    "(\n",
    "    CntMeanStdTransformer(lags=[1, 2, 3, 0])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLagTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, feature, lags):\n",
    "        self.feature = feature\n",
    "        self.lags = lags\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        sorted_data = (\n",
    "            X\n",
    "            [['date', 'hr', self.feature]]\n",
    "            .sort_values(['date', 'hr'])\n",
    "        )\n",
    "        \n",
    "        for lag in self.lags:\n",
    "            sorted_data = (\n",
    "                sorted_data\n",
    "                .assign(**{\n",
    "                    f'{self.feature}_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}']\n",
    "                        .shift(lag)\n",
    "                    )\n",
    "                })\n",
    "            )\n",
    "            \n",
    "        return (\n",
    "            # We sorted, so we have to restore the original ordering\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                sorted_data,\n",
    "                how='left',\n",
    "                on=['date', 'hr']\n",
    "            )\n",
    "            .drop(columns=['date', 'hr', self.feature])\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = []\n",
    "        for lag in self.lags:\n",
    "            feature_names.append(f'{self.feature}_{lag}h_lag')\n",
    "        return feature_names\n",
    "\n",
    "(\n",
    "    FeatureLagTransformer('hum', lags=[1, 2, 3])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficStateTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    For working days:\n",
    "        - [7, 9] U [16, 19] - rush hour\n",
    "        - [10, 15] U [20, 21] - usual traffic\n",
    "        - [0, 6] U [22, 23] - low traffic\n",
    "        \n",
    "    For non-working days:\n",
    "        - [11, 17] - rush hour\n",
    "        - [9, 10] U [18, 20] - usual traffic\n",
    "        - [0, 8] U [21, 23] - low traffic\n",
    "    \"\"\"\n",
    "    \n",
    "    traffic_by_hour = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                True: (\n",
    "                    ['low_traffic'] * 7 \n",
    "                    + ['rush_hour'] * 3 \n",
    "                    + ['usual_traffic'] * 6 \n",
    "                    + ['rush_hour'] * 4\n",
    "                    + ['usual_traffic'] * 2\n",
    "                    + ['low_traffic'] * 2\n",
    "                ),\n",
    "                False: (\n",
    "                    ['low_traffic'] * 9\n",
    "                    + ['usual_traffic'] * 2\n",
    "                    + ['rush_hour'] * 7\n",
    "                    + ['usual_traffic'] * 3\n",
    "                    + ['low_traffic'] * 3\n",
    "                )\n",
    "            },\n",
    "            index=pd.Int64Index(np.arange(24), name='hr'),\n",
    "            columns=pd.Index([True, False], name='workingday')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (\n",
    "            X\n",
    "            [['hr', 'workingday']]\n",
    "            .assign(\n",
    "                traffic_state=lambda x: x.apply(\n",
    "                    lambda y: (\n",
    "                        TrafficStateTransformer.traffic_by_hour\n",
    "                        .loc[y['hr'], y['workingday'] == 1]\n",
    "                    ),\n",
    "                    axis='columns'\n",
    "                )\n",
    "            )\n",
    "            .drop(columns=['hr', 'workingday'])\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        return ['traffic_state']\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(TrafficStateTransformer.__doc__)\n",
    "    display(TrafficStateTransformer.traffic_by_hour.T)\n",
    "    display(\n",
    "        X_train\n",
    "        .set_index(['date', 'hr'], drop=False)\n",
    "        .groupby('workingday', as_index=False)\n",
    "        .head(24)\n",
    "        .pipe(TrafficStateTransformer().transform)\n",
    "        .transpose()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CntYearlyChange(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean_change = None\n",
    "        self.std_change = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise RuntimeError('Target feature is required for fitting')\n",
    "            \n",
    "        self.mean_change, self.std_change = (\n",
    "            pd.concat(\n",
    "                [X[['yr', 'mnth']], y],\n",
    "                axis='columns',\n",
    "                sort=False\n",
    "            )\n",
    "            .groupby(['yr', 'mnth'])\n",
    "            ['cnt']\n",
    "            .agg(['mean', 'std'])\n",
    "            .unstack('yr')\n",
    "            .swaplevel(axis='columns')\n",
    "            .pipe(lambda x: x[1] - x[0])\n",
    "            .mean()\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.mean_change is None or self.std_change is None:\n",
    "            raise RuntimeError('Need to fit() first!')\n",
    "            \n",
    "        return (\n",
    "            X[['yr']]\n",
    "            .assign(\n",
    "                cnt_yearly_mean_change=lambda x: self.mean_change * x['yr'],\n",
    "                cnt_yearly_std_change=lambda x: self.std_change * x['yr']\n",
    "            )\n",
    "            .drop(columns='yr')\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        return ['cnt_yearly_mean_change', 'cnt_yearly_std_change']\n",
    "    \n",
    "(\n",
    "    CntYearlyChange()\n",
    "    .fit_transform(X_train, y_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedFeaturesPipeline(Pipeline):\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = in_names\n",
    "        for step_name, step in self.steps:\n",
    "            try:\n",
    "                feature_names = step.get_feature_names(feature_names)\n",
    "            except AttributeError as exc:\n",
    "                print(f'Beware: {step_name} does not have get_feature_names(): {exc}')\n",
    "        return feature_names\n",
    "    \n",
    "class NamedFeaturesFeatureUnion(FeatureUnion):\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = []\n",
    "        for step_name, step in self.transformer_list:\n",
    "            feature_names.extend(step.get_feature_names(in_names))\n",
    "        return feature_names\n",
    "\n",
    "class NamedFeaturesColumnTransformer(ColumnTransformer):\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        passthrough_features = []\n",
    "        if in_names is not None:\n",
    "            passthrough_features = list(in_names)\n",
    "        else:\n",
    "            passthrough_features = []\n",
    "            \n",
    "        feature_names = []\n",
    "        for step_name, step, step_features in self.transformers_:\n",
    "            if step_name == 'remainder':\n",
    "                continue\n",
    "            passthrough_features = (\n",
    "                [x for x in passthrough_features if x not in step_features]\n",
    "            )\n",
    "            print(f'At {step_name} with features {step_features}')\n",
    "            feature_names.extend(step.get_feature_names(step_features))\n",
    "            \n",
    "        if self.remainder == 'passthrough':\n",
    "            feature_names.extend(passthrough_features)\n",
    "        return feature_names\n",
    "\n",
    "class NamedFeaturesNotChangedMixin:\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        return in_names\n",
    "    \n",
    "class NamedFeaturesSimpleImputer(NamedFeaturesNotChangedMixin, SimpleImputer):\n",
    "    pass\n",
    "\n",
    "class NamedFeaturesStandardScaler(NamedFeaturesNotChangedMixin, StandardScaler):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basic_features_pipeline():\n",
    "    return NamedFeaturesColumnTransformer(\n",
    "            [\n",
    "                (\n",
    "                    'numerical_features',\n",
    "                    NamedFeaturesPipeline([\n",
    "                        ('imputer', NamedFeaturesSimpleImputer(strategy='mean')),\n",
    "                        ('scaler', NamedFeaturesStandardScaler())\n",
    "                    ]),\n",
    "                    ['temp', 'hum', 'windspeed']\n",
    "                ),\n",
    "                (\n",
    "                    'categorical_features',\n",
    "                    NamedFeaturesPipeline([\n",
    "                        ('imputer', NamedFeaturesSimpleImputer(strategy='most_frequent')),\n",
    "                        (\n",
    "                            'onehot', \n",
    "                            OneHotEncoder(\n",
    "                                categories='auto', \n",
    "                                sparse=False, \n",
    "                                handle_unknown='ignore'\n",
    "                            )\n",
    "                        )\n",
    "                    ]),\n",
    "                    ['hr', 'yr', 'mnth', 'season', 'weekday', 'weathersit']\n",
    "                ),\n",
    "                (\n",
    "                    'unmodified_features',\n",
    "                    NamedFeaturesSimpleImputer(strategy='most_frequent'),\n",
    "                    ['holiday', 'workingday']\n",
    "                )\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_features_pipeline():\n",
    "    return NamedFeaturesFeatureUnion([\n",
    "        (\n",
    "            'numerical_features', \n",
    "            NamedFeaturesPipeline([\n",
    "                (\n",
    "                    'custom_numerical_features',\n",
    "                    NamedFeaturesFeatureUnion([\n",
    "                        (\n",
    "                            'cnt_mean_std', \n",
    "                            CntMeanStdTransformer(lags=[0, 1, 2, 3, 6, 12])\n",
    "                        ),\n",
    "                        (\n",
    "                            'hum_mean_std', \n",
    "                            FeatureMeanStdTransformer('hum', lags=[0, 1, 2, 3, 6, 12])\n",
    "                        ),\n",
    "                        (\n",
    "                            'temp_mean_std', \n",
    "                            FeatureMeanStdTransformer('temp', lags=[0, 1, 2, 3, 6, 12])\n",
    "                        ),\n",
    "\n",
    "                        (\n",
    "                            'hum_lag', \n",
    "                            FeatureLagTransformer('hum', lags=[1, 2, 3])\n",
    "                        ),\n",
    "                        (\n",
    "                            'temp_lag', \n",
    "                            FeatureLagTransformer('temp', lags=[1, 2, 3])\n",
    "                        ),\n",
    "                        (\n",
    "                            'windspeed_lag', \n",
    "                            FeatureLagTransformer('windspeed', lags=[1, 2, 3])\n",
    "                        ),\n",
    "#                         (\n",
    "#                             'cnt_yearly_change',\n",
    "#                             CntYearlyChange()\n",
    "#                         )\n",
    "                    ])\n",
    "                ),\n",
    "                ('imputer', NamedFeaturesSimpleImputer(strategy='mean')),\n",
    "                ('scaler', NamedFeaturesStandardScaler())\n",
    "            ])\n",
    "        ),\n",
    "        (\n",
    "            'categorical_features', \n",
    "            NamedFeaturesPipeline([\n",
    "                (\n",
    "                    'custom_categorical_features',\n",
    "                    NamedFeaturesFeatureUnion([\n",
    "                        (\n",
    "                            'weathersit_lag', \n",
    "                            FeatureLagTransformer('weathersit', lags=[1, 3])),\n",
    "                        (\n",
    "                            'traffic_state', \n",
    "                            TrafficStateTransformer()\n",
    "                        )\n",
    "                    ])\n",
    "                ),\n",
    "                ('imputer', NamedFeaturesSimpleImputer(strategy='most_frequent')),\n",
    "                (\n",
    "                    'onehot', \n",
    "                    OneHotEncoder(\n",
    "                        categories='auto', \n",
    "                        sparse=False, \n",
    "                        handle_unknown='ignore'\n",
    "                    )\n",
    "                )\n",
    "            ])\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_pipeline():\n",
    "    return NamedFeaturesFeatureUnion([\n",
    "        (\n",
    "            'basic_features',\n",
    "            build_basic_features_pipeline()\n",
    "        ),\n",
    "        (\n",
    "            'custom_features',\n",
    "            build_custom_features_pipeline()\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = build_features_pipeline().fit(X_train, y_train)\n",
    "feature_names = p.get_feature_names(X_train.columns)\n",
    "assert p.transform(X_train).shape[1] == len(feature_names)\n",
    "t_X_train = pd.DataFrame(p.transform(X_train), columns=feature_names)\n",
    "print('Number of features: ', len(feature_names))\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(X_train[:24])\n",
    "    display(\n",
    "        t_X_train\n",
    "        [:24]\n",
    "    )\n",
    "    display(X_train[48:72])\n",
    "    display(\n",
    "        t_X_train\n",
    "        [48:72]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(model, use_grid_search=True, **grid_search_params):\n",
    "    pipeline = Pipeline([\n",
    "        ('features', build_features_pipeline()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    if use_grid_search:\n",
    "        grid_search_params = {\n",
    "            'cv': TimeSeriesSplit(n_splits=5),\n",
    "\n",
    "            **grid_search_params\n",
    "        }\n",
    "        return GridSearchCV(pipeline, **grid_search_params)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(model_name, y_true, y_pred):\n",
    "    rmse = math.sqrt(\n",
    "        mean_squared_error(y_true, y_pred)\n",
    "    )\n",
    "    print(f'{model_name} RMSE: ', rmse)\n",
    "    print(f'{model_name} R2 score: ', r2_score(y_true, y_pred))\n",
    "    sns.relplot(\n",
    "        x=model_name,\n",
    "        y='true values',\n",
    "        data=pd.DataFrame({\n",
    "            'true values': y_true,\n",
    "            model_name: y_pred\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, model, **grid_search_params):\n",
    "    use_grid_search = 'param_grid' in grid_search_params\n",
    "    pipeline = build_pipeline(\n",
    "        model,\n",
    "        use_grid_search=use_grid_search,\n",
    "        **grid_search_params\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print('On Train dataset:')\n",
    "    evaluate_prediction(model_name, y_train, pipeline.predict(X_train))\n",
    "    print('On Test dataset:')\n",
    "    evaluate_prediction(model_name, y_test, pipeline.predict(X_test))\n",
    "    if use_grid_search:\n",
    "        print('Best params: ', pipeline.best_params_)\n",
    "        estimator = pipeline.best_estimator_\n",
    "    else:\n",
    "        estimator = pipeline\n",
    "    \n",
    "    if hasattr(estimator['model'], 'feature_importances_'):\n",
    "        feature_importance = (\n",
    "            pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': estimator['model'].feature_importances_\n",
    "            })\n",
    "            .sort_values(by='importance', ascending=False)\n",
    "            .nlargest(20, columns='importance')\n",
    "        )\n",
    "\n",
    "        g = sns.catplot(\n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            kind='bar',\n",
    "            aspect=2,\n",
    "            data=feature_importance\n",
    "        )\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        g.fig.suptitle(f'Feature importance of {model_name}')\n",
    "        g.fig.savefig(\n",
    "            os.path.join(\n",
    "                FIGURES_PATH, \n",
    "                f'{model_name.replace(\" \", \"-\")}-feature-importance.png'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest = evaluate_model(\n",
    "    'random forest',\n",
    "    RandomForestRegressor(\n",
    "        random_state=42, \n",
    "        n_estimators=1000, \n",
    "        max_depth=20, \n",
    "        max_features=0.5\n",
    "    ),\n",
    "#     param_grid={\n",
    "#         'model__n_estimators': [750, 1000, 1250],\n",
    "#         'model__max_depth': [20, 30],\n",
    "#         'model__max_features': [0.5]\n",
    "#     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbr = evaluate_model(\n",
    "    'gradient boosting',\n",
    "    GradientBoostingRegressor(\n",
    "        random_state=42, \n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.5\n",
    "    ),\n",
    "#     param_grid={\n",
    "#         'model__n_estimators': [450, 500, 550, 600, 650, 700, 750, 800],\n",
    "#         'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "#         'model__subsample': [0.5, 1]\n",
    "#     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_feature(data):\n",
    "    return (\n",
    "        data\n",
    "        .assign(datetime=lambda x: (\n",
    "            x.apply(\n",
    "                lambda y: (\n",
    "                    y['date'].replace(hour=y['hr'])\n",
    "                ), \n",
    "                axis='columns'\n",
    "            )\n",
    "        ))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = (\n",
    "    pd.DataFrame({\n",
    "        'y_true': y_test,\n",
    "        'y_pred': gbr.predict(X_test),\n",
    "        'date': X_test['date'],\n",
    "        'hr': X_test['hr']\n",
    "    })\n",
    "    .pipe(add_datetime_feature)\n",
    "    .drop(columns=['date', 'hr'])\n",
    "    .melt(id_vars=['datetime'], value_vars=['y_true', 'y_pred'])\n",
    "    \n",
    "    [lambda x: x['datetime'] < '2012-05-30']\n",
    ")\n",
    "\n",
    "model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    x='datetime',\n",
    "    y='value',\n",
    "    hue='variable',\n",
    "    kind='line',\n",
    "    palette={\n",
    "        'y_true': 'C0',\n",
    "        'y_pred': 'C3'\n",
    "    },\n",
    "    aspect=2,\n",
    "    data=model_predictions\n",
    ")\n",
    "\n",
    "g.fig.suptitle('True and predicted values for the number of ambulance calls')\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.set(\n",
    "    ylabel='Number of ambulance calls',\n",
    "    xlabel='Date and hour'\n",
    ")\n",
    "g._legend.texts[0].set_text('Number of calls')\n",
    "g._legend.texts[1].set_text('True value')\n",
    "g._legend.texts[2].set_text('Predicted value')\n",
    "\n",
    "g.fig.savefig(os.path.join(FIGURES_PATH, 'true-predicted-cnt.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
