---
layout: default
title: Analyse des d√©pendances entre les √©tapes de build
date: 2022-11
---

## Authors

Nous sommes quatre √©tudiants en derni√®re ann√©e de M2 Nice-Sophia sp√©cialis√©s en architecture logicielle :

- KHERROUBI Abdelkader ([@abdelkader1996](https://github.com/abdelkader1996)),
- SI DEHBI Ahmed El Hanafi ([@AhmedElHanafi](https://github.com/AhmedElHanafi)),
- NAJI Abdellah ([@abdellah07](https://github.com/abdellah07)),
- HERAUD Antoine  ([@herauda](https://github.com/herauda)).

## I. Contexte de recherche 

***Docker*** est une plateforme de conteneurs permettant d‚Äôembarquer des applications dans des environnements d‚Äôex√©cution l√©gers afin d‚Äôen cr√©er des instances facilement ou de pouvoir isoler compl√®tement les logiques entre applications. La mont√©e en utilisation de services *cloud* pour le d√©ploiement d‚Äôapplications a popularis√© l‚Äôutilisation de *Docker*, √©tant l‚Äôune des meilleure solution pour conteneuriser ses applications. Cependant, la mani√®re dont sont interpr√©t√©s les *Dockerfile*, fichier d√©crivant la construction d'une image *Docker*, peut √™tre consid√©r√©e comme valide par le moteur mais pourrait tout de m√™me r√©sulter en un √©chec lors de l'ex√©cution de l‚Äôapplication pour de multiples raisons.

  

Ainsi dans ce projet, nous souhaitons examiner les *Dockerfile* d√©crivant des images utilis√©es par des *workflows*, qui d√©crivent eux-m√™me la construction d'une application, afin d‚Äô√©tablir un degr√© de certitude quant √† la stabilit√© de ce *build*. Nous chercherons √† savoir si les commandes d√©crites dans un *Dockerfile* peuvent nous permettre d‚Äô√©tablir une liste de ses d√©pendances et de valider leur pr√©sence, et d‚Äôattribuer un score selon le taux de d√©pendances v√©rifi√©es. Nous chercherons √©galement √† trouver d‚Äô√©ventuelles probl√®mes de description de *Dockerfile*, c'est-√†-dire des mauvaises pratiques de syntaxe, qui pourraient nous emp√™cher d‚Äôanalyser correctement ce dernier et mesurer l'impact de ces derniers sur la stabilit√© g√©n√©rale des *builds* *Docker*.

## II. Observations et Question g√©n√©rale

Face au grand nombre de projets *Dockeris√©s* dans l‚Äôensemble des applications modernes, nous nous sommes pos√© la question suivante :

**Comment d√©terminer la stabilit√© du *build* *Docker* d'une application √† partir de l'analyse de ses d√©pendances ?**

Nous chercherons donc √† savoir si le *build* *Docker* d'une application, d√©crit dans un fichier de *workflow* par un certain nombre d‚Äô√©tapes, peut √™tre analys√© au pr√©alable afin de valider que ce dernier est stable : il doit √™tre reproductible et invariant. Nous chercherons √† analyser les fichiers *Dockerfile* d√©crits utilis√©s par les √©tapes de *build* du *workflow* analys√© et valider que les d√©pendances d√©crites par ces *Dockerfile* sont pr√©sentes.

L‚Äôensemble des pratiques emp√™chant la visibilit√© sur les d√©pendances n√©cessaires sera consid√©r√© comme participant √† l‚Äôinstabilit√© du projet.

*Docker* √©tant largement utilis√© aujourd‚Äôhui, nous pensons que les r√©sultats √† cette question de recherche pourraient servir aux acteurs produisant des applications *Dockeris√©es* et que l‚Äôanalyse pr√©alable de la stabilit√© des builds pourrait b√©n√©ficier √† ces acteurs, afin d‚Äôam√©liorer la stabilit√© globale des builds *Docker*.

Afin de r√©pondre √† cette question de recherche, nous nous sommes pos√© les questions suivantes : 

1.  Comment identifier les diff√©rentes d√©pendances dans un *Dockerfile*?
    
2.   Comment valider la stabilit√© d‚Äôun build *Docker* dans son ensemble √† l'aide des √©tapes de son *workflow*?
    
3.  Comment relever les diff√©rentes mauvaises pratiques emp√™chant une meilleure analyse?
    


## III. Collecte d'informations

Afin de pouvoir r√©pondre √† nos questions de recherche, nous avons cherch√© des projets correspondant √† certains crit√®res afin que nous puissions y effectuer notre analyse. Nous avons premi√®rement recherch√© les projets les plus populaires de *DockerHub* (ayant plus de 500 √©toiles), qui utiliseraient donc des *Dockerfile*, et avons s√©lectionn√© les projets dont les *workflows* de build √©taient publics, dans notre cas pr√©sent sur *GitHub* o√π les projets sont h√©berg√©s.  
  
Une fois un √©chantillon vari√© de projets s√©lectionn√© (en termes d'utilisation et de structure), nous proc√©dons √† l‚Äôanalyse du projet gr√¢ce √† plusieurs scripts *Python* : un script sera charg√© de parser le contenu des fichiers de *workflow*, un autre sera charg√© de d√©terminer l‚Äôensemble des d√©pendances pour un *Dockerfile* et un dernier aura pour r√¥le d‚Äôagglom√©rer les donn√©es et produire des informations d‚Äôanalyse pour l‚Äôutilisateur.  
  
  

## IV. Hypoth√®ses et exp√©riences

### 1. Comment identifier les diff√©rentes d√©pendances dans un *Dockerfile*?

**Hypoth√®se :**  

Les d√©pendances que nous consid√©rons dans notre √©tude devront √™tre limit√©es selon certains crit√®res si nous souhaitons offrir un haut degr√© de pr√©cision pour ces derni√®res. Ainsi, nous nous limiterons √† la pr√©sence de fichiers mentionn√©s dans les *Dockerfile* et aux utilisations qui pourraient en √™tre faite par diff√©rents scripts. Nous pensons donc que ces fichiers impliqu√©s dans les *builds* repr√©sentent la forme de d√©pendance la plus stricte :  ces fichiers doivent √™tre pr√©sents s'ils sont utilis√©s, sans quoi le *build* sera en √©chec. Si leur pr√©sence ne peut √™tre v√©rifi√©e, on consid√©rera la d√©pendance comme absente. Nous consid√©rerons √©galement les dossiers utilis√©s dans les commandes *Docker* comme des d√©pendances, au m√™me titre que les fichiers, car l'utilisation de r√©pertoire n'offre pas de visibilit√© √† notre outil.


**Exp√©rience :** 

Nous allons donc effectuer un *parsing* des *Dockerfile* pour y chercher des commandes `COPY` et `ADD` qui manipulent des fichiers ou des archives. En effectuant ce *parsing*, nous stockons le nom des fichiers consid√©r√©s comme d√©pendances au sein des *builds*, que nous v√©rifierons contre le syst√®me de fichiers √† l‚Äô√©tape suivante. Ceci nous permet de d√©terminer quels √©l√©ments √† analyser et √† attribuer des validations ou des alertes.

  

### 2. Comment valider la stabilit√© d‚Äôun build *Docker* dans son ensemble √† l'aide des √©tapes de son *workflow*?

**Hypoth√®se :**  

Pour cette exp√©rience, il nous faudra examiner les √©tapes du *workflow* du projet en cours d‚Äôanalyse et d√©terminer lesquelles utilisent des *Dockerfile*, que nous pouvons analyser gr√¢ce √† l‚Äô√©tape pr√©c√©dente. Gr√¢ce √† l‚Äôagglom√©ration des d√©pendances des *Dockerfile*, nous pouvons en d√©duire l‚Äôensemble des d√©pendances n√©cessaires √† l‚Äôex√©cution d‚Äôune √©tape. Ainsi, en analysant les *Dockerfile* composant un *workflow*, nous pouvons v√©rifier la validit√© de leurs d√©pendances (leur existence pour des fichiers) et calculer le degr√© de stabilit√© d‚Äôun *workflow*, bas√© sur les *Dockerfile* utilis√©s par ses diff√©rentes √©tapes.

Si un projet poss√®de un nombre trop √©lev√© de d√©pendances √† risque, donc non v√©rifiables, ce dernier sera consid√©r√© comme instable. Le taux exact de d√©pendances √† risque reste encore √† d√©terminer et n√©cessitera une analyse de nombreux projets. Nous partons √©galement du principe que les steps du *workflow* seront visibles √† l‚Äôanalyse, et allons donc pour notre cas utiliser uniquement des projets ayant des *workflows*  *GitHub* publics auxquels nous aurons acc√®s. D‚Äôautres outils tels que Jenkins pourraient √©galement √™tre analys√©s mais cet outil est largement utilis√© par des organismes priv√©s sur des pipelines auxquelles nous n‚Äôaurions pas acc√®s.  
  

**Exp√©rience :** 

Le but de cette exp√©rience serait de montrer que nous pouvons √©largir notre analyse au projet entier en examinant les √©tapes de son *workflow*. En examinant les √©tapes et les *Dockerfile* qu‚Äôelles mentionnent, nous pouvons √©tablir un taux de stabilit√© global √† l‚Äôensemble du *workflow*.

Afin de mener √† bien cette exp√©rience, nous analysons un build poss√©dant toutes ses d√©pendances et validons que son build est stable, avec un taux de stabilit√© que nous notons. Nous effectuons la m√™me analyse sur le *workflow* et que ce dernier a toutes ses d√©pendances stables. Ensuite, nous modifions un *Dockerfile* pour qu'il poss√®de une d√©pendance manquante, et validons que ce dernier est marqu√© comme instable car manquant une d√©pendance. Nous effectuons ensuite √† nouveau l‚Äôanalyse sur le *workflow* et validons que ce dernier est d√©sormais marqu√© comme instable car une de ses d√©pendances, un *Dockerfile*, poss√®de lui-m√™me une d√©pendance manquante. Nous restaurons ensuite le fichier et validons que le *build* est redevenu stable, avec un taux de stabilit√© √©gal au taux avant modification.

Une fois la fonctionnalit√© valid√©e, nous pouvons effectuer cette analyse sur les d√©p√¥ts que nous avons choisis et comparer les r√©sultats produits.

  

### 3. Comment relever diff√©rentes mauvaises pratiques emp√™chant une meilleure analyse?

**Hypoth√®se :** 

Nous partons du principe que toutes les mauvaises pratiques ne sont pas connues et peuvent aussi √™tre arbitraires, mais certaines nous indiquent une impossibilit√© de v√©rification, tels que des commandes `COPY . .` , qui masquent des fichiers derri√®re un chemin inv√©rifiable et que nous ne pouvons donc pas valider. Certains scripts peuvent √©galement renommer certains fichiers et la v√©rification de ces derniers n√©cessiterait une analyse extensive de ces scripts, ce qui s‚Äô√©loignerait de l‚Äôobjectif initial de notre √©tude et de la cr√©ation de notre outil. Nous nous contenterons donc d‚Äôexaminer les quelques mauvaises pratiques les plus courantes et pourront faire √©voluer notre √©tude selon de nouvelles donn√©es.  

**Exp√©rience :** 

L‚Äôexp√©rience serait d‚Äôanalyser un haut nombre de *Dockerfile* et de rep√©rer parmi ces derniers quelles seraient les mauvaises pratiques les plus fr√©quentes. Cela serait √©videmment limit√© aux mauvaises pratiques que nous d√©finirions et pourrait donc √™tre donc limit√©. Il nous faudrait ainsi mettre cette exp√©rience √† jour avec une recherche plus compl√®te des mauvaises pratiques durant l‚Äô√©criture de *Dockerfile*.

Nous chercherons √† valider que notre outil permet de reconna√Ætre de telles mauvaises pratiques et que les builds concern√©s soient marqu√©s comme en alerte. Nous pourrions √©galement chercher √† valider qu‚Äôune mauvaise pratique, telle qu‚Äôune commande `COPY . .`, pourrait mener un *build* √† l‚Äô√©chec sans que nous puissions le valider. Nous placerions un dossier vide l√† o√π un build aurait besoin d‚Äôun fichier, tout en effectuant une commande `COPY . .` qui serait accept√© par le moteur *Docker*, et qui provoquerait une erreur lors de l‚Äôex√©cution de l‚Äôapplication.

Nous pourrions √©galement fournir des recommandations et des alertes plus sp√©cifiques si nous choisissons d‚Äôeffectuer plus de recherches sur ce sujet.  
  

## V. Analyse des r√©sultats et conclusion

### 1. Comment identifier les diff√©rentes d√©pendances dans un *Dockerfile*?

Apr√®s analyse des projets s√©lectionn√©s par notre outil, nous observons les proportions suivantes de commandes *Docker* au sein des *Dockerfiles* : 

![Figure 1 - R√©sultat de l'analyse des commandes Docker](assets/images/docker-command-graph.png)

On peut voir que les projets font majoritairement usage de la commande `COPY`, avec 10 commandes `COPY` en moyenne par *Dockerfile*. Nous avons dans nos √©chantillons des projets de petite et grande taille : *Moby* et *Postgris* √©tant des projets de grande taille, ces derniers font usage de la commande `RUN` plus fr√©quemment, avec 35 commandes `COPY` contre 70 `RUN` pour *Moby* et 3 `COPY` contre 19 `RUN` pour *Postgris*. Pour l'analyse des d√©pendances, nous nous limiterons cependant 

Nous consid√©rons donc les commandes `COPY` comme des d√©pendances de notre *Dockerfile* et apr√®s analyse des fichiers et dossiers mentionn√©s, nous obtenons les r√©sultats suivants : 

![Figure 2 - R√©sultat de l'analyse des d√©pendances Docker](assets/images/docker-dependency-graph.png)

On peut remarquer que les projets *Moby* et *OpenZipkin*, qui pr√©sentent plus de d√©pendances que les autres projets, ont une majorit√© de d√©pendances sous forme de dossiers, ce qui permet de rendre les commandes plus compactes en √©vitant de copier les fichiers un √† un. Cependant, cela peut parfois masquer des d√©pendances non r√©solues, comme un fichier manquant attendu dans un dossier copi√©.  On constate √©galement que les projets de plus petite taille ont plus tendance √† copier les fichiers par nom. 
  

  

### 2. Comment valider la stabilit√© d‚Äôun build *Docker* dans son ensemble √† l'aide des √©tapes de son *workflow*?

Apr√®s avoir analys√© les *workflows* des projets s√©lectionn√©s, en associant certaines de leurs √©tapes avec les *Dockerfile* qu'elles utilisent et leurs d√©pendances, nous analysons le projet pour v√©rifier l'existence des d√©pendances mentionn√©es et obtenons les r√©sultats suivants : 

![Figure 3 - R√©sultat de l'analyse des workflows et d√©pendances Docker et v√©rification](assets/images/docker-dependency-validation-graph.png)

Nous pouvons voir sur ce graphique que la majorit√© des d√©pendances ont pu √™tre v√©rifi√©es pour chaque projet mais que ces derniers pr√©sentent tous des d√©pendances qui n'ont pas pu √™tre v√©rifi√©es. Ces d√©pendances peuvent ne pas avoir √©t√© pr√©sentes ou peuvent avoir √©t√© masqu√©es derri√®re des mauvaises pratiques et soient donc inv√©rifiables. 

Gr√¢ce √† ces donn√©es, nous pouvons √©tablir le taux de stabilit√© pour chacun des projets : 

![Figure 4 - R√©sultat du taux de stabilit√© des projets](assets/images/docker-stability-graph.png)

Nous constatons que les taux de stabilit√© des projets sont relativement vari√©s et que certains d'entre eux doivent donc pr√©senter des descriptions *Docker* plus pr√©cises : nos deux projets les plus cons√©quents pr√©sentent le taux de stabilit√© le plus bas (*OpenZipkin*) et l'un des plus √©lev√©s (*Moby*), et nous pouvons faire r√©f√©rence √† l'exp√©rience pr√©c√©dente qui pr√©sentait *OpenZipkin* comme ayant beaucoup de d√©pendances sous forme de dossiers. Nous pouvons imaginer que ces dossiers absents sont g√©n√©r√©s au cours du *build* mais nous ne pouvons v√©rifier cette hypoth√®se sans nous √©loigner de notre objectif initial. 

  

### 3. Comment relever diff√©rentes mauvaises pratiques emp√™chant une meilleure analyse?

2.  Interpr√©tation/Analyse des r√©sultats en fonction de vos hypoth√®ses  
      
    
3.  Construction d‚Äôune conclusion  
      
    üí° Vos r√©sultats et donc votre analyse sont n√©cessairement limit√©s. Pr√©ciser bien ces limites : par exemple, jeux de donn√©es insuffisants, analyse r√©duite √† quelques crit√®res, d√©pendance aux projets analys√©s, ‚Ä¶  
      
    

  
  

## VI. Outils

Pour les recherches sur l‚Äôanalyse de d√©pendances *Docker* que nous avons effectu√©, il nous a fallu d√©velopper un outil permettant d‚Äôanalyser ces d√©pendances au sein de fichiers *Dockerfile* en recoupant leur utilisation faite par les diff√©rents *workflows* de *build* de l‚Äôapplication analys√©e. Cette derni√®re devait √©galement permettre de d√©tecter diff√©rentes anomalies selon les d√©pendances analys√©es (absence de fichiers, ex√©cution de scripts?) ou non (mauvaises pratiques).

A cet effet nous avons √©crit un script *python* effectuant ces op√©rations :

-   *Parsing* d‚Äôun fichier de *workflow* sp√©cifi√© en entr√©e et recherche d‚Äô√©tapes mentionnant l‚Äôutilisation de *Dockerfile*,  
      
    
-   *Parsing* de *Dockerfile* cherchant des commandes `COPY` mentionnant des fichiers :
    

	-   Le chemin est atteignable et nous pouvons v√©rifier leur existence donc *valide*,
    
	-   Le chemin n‚Äôest pas atteignable et il est impossible de v√©rifier donc *danger*,
    
	-   Le chemin est atteignable mais le fichier ne s‚Äôy trouve pas donc *alerte*.  
   Il est cependant possible que le fichier mentionn√© soit produit lors du build mais sans v√©rification certaine cela reste une *alerte*.
    

- Recherche de commandes `ADD` mentionnant fichiers, qui suivra le m√™me traitement que `COPY`, ou des archives dont la pr√©sence sera v√©rifi√©e √©galement.

- Durant ce *parsing*, le script analyse √©galement les commandes pour d√©terminer si elles repr√©sentent une mauvaise pratique et seront remont√©es en tant que zones de danger car elles apportent de l‚Äôincertitude √† notre analyse.

- Une fois ces d√©pendances analys√©es, nous chercherons √† valider la pr√©sence des fichiers ou des archives mentionn√©s. Pour cela, nous effectuons une v√©rification dans le dossier du projet de l‚Äôexistence des fichiers n√©cessaires. S‚Äôils ne sont pas trouv√©s, la d√©pendance est not√©e comme absente.  
  
- Une fois les d√©pendances pr√©sentes et absentes cat√©goris√©es, nous calculons le taux de stabilit√© pour chaque *Dockerfile*, et pour chaque √©tape du *workflow* les utilisant.

- L‚Äôoutil affiche les donn√©es concernant la stabilit√© du projet analys√© √† l‚Äôutilisateur.  
  
  

## VI. R√©f√©rences

1. [Debret 2020] Debret, J. (2020) La d√©marche scientifique : tout ce que vous devez savoir ! Available at: [https://www.scribbr.fr/article-scientifique/demarche-scientifique/](https://www.scribbr.fr/article-scientifique/demarche-scientifique/) (Accessed: 18 November 2022).

2. Notre outil *Python*: [Dockerfile-Analyser](https://github.com/AhmedElHanafi/Dockerfile-Analyser) est un outil d√©velopp√© par l'√©quipe dans le but d'analyser les d√©pendances utilis√©es dans les *Dockerfile* et *workflows*, et de valider la pr√©sence de ces derni√®res.

3. Projets avec *build Docker* utilis√©s apr√®s recherche sur [*Dockerhub*](https://hub.docker.com/) et *GitHub* :  
	- [Docker Postgris Project](https://github.com/kartoza/docker-postgis)  
	-  [Moby Project](https://github.com/moby/moby)
    -   [Camuflon - API](https://github.com/camuflon/camuflon-api)
    -   [Desafio Backend](https://github.com/uandisson/desafio_backend)
    -   [OpenZipkin](https://github.com/openzipkin/)
   
 4. Documentation sur [bonnes](https://sysdig.com/blog/dockerfile-best-practices/) et [mauvaises pratiques *Docker*](https://runnable.com/blog/9-common-dockerfile-mistakes) 
