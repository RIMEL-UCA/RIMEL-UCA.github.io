{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"c9afcd53-8957-4f07-b4fa-21d72ed09429","cell_type":"markdown","source":"# Titanic â€” Clean Feature Engineering + CV Ensemble (CatBoost / LightGBM)\n\nThis notebook:\n- Builds strong, compact features (Title, FamilySize, Deck, TicketPrefix, etc.)\n- Uses Stratified K-Fold CV with OOF probabilities\n- Tunes a classification threshold on OOF\n- Blends CatBoost + LightGBM and outputs `/kaggle/working/submission.csv`\n","metadata":{}},{"id":"19ddaa57-6338-48cf-b11c-d75a5896fff8","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nfrom catboost import CatBoostClassifier, Pool\nimport lightgbm as lgb\n\nSEED = 42\nN_SPLITS = 10\n\nTRAIN_PATH = \"/kaggle/input/titanic/train.csv\"\nTEST_PATH  = \"/kaggle/input/titanic/test.csv\"\nWORKDIR = \"/kaggle/working\"\n\nrng = np.random.default_rng(SEED)\n\npd.set_option(\"display.max_columns\", 200)\nnp.random.seed(SEED)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"2a978f14-cae5-4264-a640-92ca6c83b45e","cell_type":"code","source":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\ntrain.shape, test.shape\n","metadata":{},"outputs":[],"execution_count":null},{"id":"eda9afae-c83e-486a-933f-b09f3e86403c","cell_type":"code","source":"train.head()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"0800b480-ac13-4ea6-b553-cc93dfc69d1d","cell_type":"code","source":"def add_features(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    df[\"Pclass\"] = df[\"Pclass\"].astype(str)\n\n    title = df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n    title = title.replace({\n        \"Mlle\": \"Miss\",\n        \"Ms\": \"Miss\",\n        \"Mme\": \"Mrs\",\n        \"Lady\": \"Rare\",\n        \"Countess\": \"Rare\",\n        \"Capt\": \"Rare\",\n        \"Col\": \"Rare\",\n        \"Don\": \"Rare\",\n        \"Dr\": \"Rare\",\n        \"Major\": \"Rare\",\n        \"Rev\": \"Rare\",\n        \"Sir\": \"Rare\",\n        \"Jonkheer\": \"Rare\",\n        \"Dona\": \"Rare\",\n    })\n    vc = title.value_counts()\n    rare_titles = vc[vc < 10].index\n    title = title.replace(rare_titles, \"Rare\")\n    df[\"Title\"] = title.fillna(\"Rare\")\n\n    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n    df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n\n    df[\"CabinKnown\"] = df[\"Cabin\"].notna().astype(int)\n    df[\"Deck\"] = df[\"Cabin\"].astype(str).str[0].replace(\"n\", np.nan).fillna(\"U\")\n\n    ticket_prefix = (\n        df[\"Ticket\"]\n        .astype(str)\n        .str.replace(r\"\\d+\", \"\", regex=True)\n        .str.replace(r\"\\s+\", \"\", regex=True)\n        .str.strip()\n    )\n    ticket_prefix = ticket_prefix.replace(\"\", \"NUM\")\n    df[\"TicketPrefix\"] = ticket_prefix\n\n    df[\"FarePerPerson\"] = df[\"Fare\"] / df[\"FamilySize\"]\n    df[\"FarePerPerson\"] = df[\"FarePerPerson\"].replace([np.inf, -np.inf], np.nan)\n\n    return df\n\ndef impute(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n\n    df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode(dropna=True)[0])\n    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\n    df[\"FarePerPerson\"] = df[\"FarePerPerson\"].fillna(df[\"Fare\"].median())\n\n    g1 = df.groupby([\"Title\", \"Pclass\", \"Sex\"])[\"Age\"].median()\n    m1 = df[\"Age\"].isna()\n    if m1.any():\n        df.loc[m1, \"Age\"] = df.loc[m1, [\"Title\", \"Pclass\", \"Sex\"]].apply(lambda r: g1.get((r[\"Title\"], r[\"Pclass\"], r[\"Sex\"]), np.nan), axis=1)\n\n    g2 = df.groupby([\"Pclass\", \"Sex\"])[\"Age\"].median()\n    m2 = df[\"Age\"].isna()\n    if m2.any():\n        df.loc[m2, \"Age\"] = df.loc[m2, [\"Pclass\", \"Sex\"]].apply(lambda r: g2.get((r[\"Pclass\"], r[\"Sex\"]), np.nan), axis=1)\n\n    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n    return df\n","metadata":{},"outputs":[],"execution_count":null},{"id":"95b0773e-6ecf-403d-bc52-91f22ba402af","cell_type":"code","source":"train_fe = impute(add_features(train))\ntest_fe  = impute(add_features(test))\n\ntarget = \"Survived\"\nid_col = \"PassengerId\"\n\ndrop_cols = [target, \"Name\", \"Ticket\", \"Cabin\"]\nX = train_fe.drop(columns=drop_cols)\ny = train_fe[target].astype(int).to_numpy()\n\nX_test = test_fe.drop(columns=[c for c in drop_cols if c != target])\n\ncat_cols = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\", \"Deck\", \"TicketPrefix\"]\nfor c in cat_cols:\n    X[c] = X[c].astype(\"category\")\n    X_test[c] = X_test[c].astype(\"category\")\n\nX.shape, X_test.shape\n","metadata":{},"outputs":[],"execution_count":null},{"id":"01fad8a5-f1b5-4e2e-9d85-7f52d44d8bae","cell_type":"markdown","source":"## Quick EDA (compact visuals)\n","metadata":{}},{"id":"f29bbb51-0ab1-4b91-8ffe-985ad49255ac","cell_type":"code","source":"miss = train.isna().mean().sort_values(ascending=False)\nplt.figure(figsize=(8,4))\nplt.bar(miss.index[:10], miss.values[:10])\nplt.xticks(rotation=45, ha=\"right\")\nplt.title(\"Top missing-rate columns (train)\")\nplt.tight_layout()\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"80f8f94c-9b86-41c9-82f2-087b80bcf10c","cell_type":"code","source":"tmp = train_fe.copy()\ntmp[\"Pclass\"] = tmp[\"Pclass\"].astype(str)\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 3.5))\n\naxes[0].bar(tmp.groupby(\"Sex\")[\"Survived\"].mean().index, tmp.groupby(\"Sex\")[\"Survived\"].mean().values)\naxes[0].set_title(\"Survival rate by Sex\")\n\naxes[1].bar(tmp.groupby(\"Pclass\")[\"Survived\"].mean().index, tmp.groupby(\"Pclass\")[\"Survived\"].mean().values)\naxes[1].set_title(\"Survival rate by Pclass\")\n\naxes[2].bar(tmp.groupby(\"Embarked\")[\"Survived\"].mean().index, tmp.groupby(\"Embarked\")[\"Survived\"].mean().values)\naxes[2].set_title(\"Survival rate by Embarked\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"9775257b-387b-4265-a732-c87de3d566cb","cell_type":"code","source":"def tune_threshold(y_true, proba):\n    ths = np.linspace(0.05, 0.95, 181)\n    best_t = 0.5\n    best_a = -1.0\n    for t in ths:\n        a = accuracy_score(y_true, (proba >= t).astype(int))\n        if a > best_a:\n            best_a = a\n            best_t = float(t)\n    return best_t, float(best_a)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"e56fbf12-e5e0-4899-9e31-0fce30c3fbdf","cell_type":"code","source":"skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\noof_cb = np.zeros(len(X), dtype=float)\ntest_cb = np.zeros(len(X_test), dtype=float)\n\ncat_idx = [X.columns.get_loc(c) for c in cat_cols]\n\nfor fold, (trn, val) in enumerate(skf.split(X, y), 1):\n    X_tr, X_va = X.iloc[trn], X.iloc[val]\n    y_tr, y_va = y[trn], y[val]\n\n    tr_pool = Pool(X_tr, y_tr, cat_features=cat_idx)\n    va_pool = Pool(X_va, y_va, cat_features=cat_idx)\n    te_pool = Pool(X_test, cat_features=cat_idx)\n\n    m = CatBoostClassifier(\n        loss_function=\"Logloss\",\n        eval_metric=\"Accuracy\",\n        iterations=20000,\n        learning_rate=0.03,\n        depth=7,\n        l2_leaf_reg=5.0,\n        subsample=0.85,\n        colsample_bylevel=0.85,\n        random_seed=SEED,\n        early_stopping_rounds=400,\n        verbose=False\n    )\n\n    m.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n    oof_cb[val] = m.predict_proba(va_pool)[:, 1]\n    test_cb += m.predict_proba(te_pool)[:, 1] / N_SPLITS\n\nt_cb, a_cb = tune_threshold(y, oof_cb)\na_cb, t_cb\n","metadata":{},"outputs":[],"execution_count":null},{"id":"5b625f6d-9f32-4dbc-b31d-f647a2fb4f4b","cell_type":"code","source":"pred_cb = (oof_cb >= t_cb).astype(int)\ncm = confusion_matrix(y, pred_cb)\ncm\n","metadata":{},"outputs":[],"execution_count":null},{"id":"0b311a1b-4da4-4f3e-963f-4da2d5575ebe","cell_type":"code","source":"plt.figure(figsize=(4,4))\nplt.imshow(cm)\nplt.title(\"CatBoost OOF Confusion Matrix\")\nplt.xticks([0,1], [\"Pred 0\", \"Pred 1\"])\nplt.yticks([0,1], [\"True 0\", \"True 1\"])\nfor i in range(2):\n    for j in range(2):\n        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\nplt.tight_layout()\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"caf1cbe4-699d-421d-b4c2-9a7e225313f7","cell_type":"code","source":"skf2 = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\noof_lgb = np.zeros(len(X), dtype=float)\ntest_lgb = np.zeros(len(X_test), dtype=float)\n\nfor fold, (trn, val) in enumerate(skf2.split(X, y), 1):\n    X_tr, X_va = X.iloc[trn], X.iloc[val]\n    y_tr, y_va = y[trn], y[val]\n\n    m = lgb.LGBMClassifier(\n        n_estimators=20000,\n        learning_rate=0.02,\n        num_leaves=64,\n        max_depth=-1,\n        min_child_samples=25,\n        subsample=0.85,\n        colsample_bytree=0.85,\n        reg_lambda=1.0,\n        random_state=SEED\n    )\n\n    m.fit(\n        X_tr, y_tr,\n        eval_set=[(X_va, y_va)],\n        eval_metric=\"binary_logloss\",\n        callbacks=[lgb.early_stopping(400, verbose=False)]\n    )\n\n    oof_lgb[val] = m.predict_proba(X_va)[:, 1]\n    test_lgb += m.predict_proba(X_test)[:, 1] / N_SPLITS\n\nt_lgb, a_lgb = tune_threshold(y, oof_lgb)\na_lgb, t_lgb\n","metadata":{},"outputs":[],"execution_count":null},{"id":"11ac01fc-aa12-4bf8-acd8-a6ce719b91a2","cell_type":"code","source":"best = {\"acc\": -1.0, \"w\": 0.5, \"t\": 0.5}\nfor w in np.linspace(0, 1, 101):\n    p = w * oof_cb + (1 - w) * oof_lgb\n    t, a = tune_threshold(y, p)\n    if a > best[\"acc\"]:\n        best = {\"acc\": a, \"w\": float(w), \"t\": float(t)}\nbest\n","metadata":{},"outputs":[],"execution_count":null},{"id":"65346bbf-7332-4263-adf0-d67c734f6bd7","cell_type":"code","source":"w = best[\"w\"]\nt = best[\"t\"]\n\noof_blend = w * oof_cb + (1 - w) * oof_lgb\ntest_blend = w * test_cb + (1 - w) * test_lgb\n\nacc_blend = accuracy_score(y, (oof_blend >= t).astype(int))\nacc_blend, w, t\n","metadata":{},"outputs":[],"execution_count":null},{"id":"befeb9a4-e72a-4942-b6d4-5bdf55d26f4e","cell_type":"code","source":"pred_test = (test_blend >= t).astype(int)\n\nsubmission = pd.DataFrame({\n    \"PassengerId\": test[id_col].values,\n    \"Survived\": pred_test\n})\n\nout_path = f\"{WORKDIR}/submission.csv\"\nsubmission.to_csv(out_path, index=False)\n\nout_path\n","metadata":{},"outputs":[],"execution_count":null}]}