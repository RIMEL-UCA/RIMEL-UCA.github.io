{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\n\ninput_dir = '/kaggle/input/titanic/'\ntarget = 'Survived'\n\nif torch.cuda.is_available():\n    device = 'cuda:0' # first GPU available\nelse:\n    device = 'cpu'\nprint(f'Using device: {device}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:49.047231Z","iopub.execute_input":"2026-01-17T16:35:49.047444Z","iopub.status.idle":"2026-01-17T16:35:56.280879Z","shell.execute_reply.started":"2026-01-17T16:35:49.047424Z","shell.execute_reply":"2026-01-17T16:35:56.279573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# use global scaler to preserve fit for test transform\nscaler = StandardScaler()\nonehot = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n\ndef prepare(df, scaler=scaler, onehot=onehot, test_set=False):\n    df = df.drop(columns=['PassengerId', target], errors='ignore')\n\n    numerical_features = df.select_dtypes(include=np.number).columns.tolist()\n\n    df[numerical_features] = df[numerical_features].fillna(0)\n\n    # apply normalization to features (x - x.mean()) / x.std()\n    # for test set we only transform the data, otherwise we leak data and cheat = overly optimistic (inaccurate) evaluation\n    if test_set:\n        df[numerical_features] = scaler.transform(df[numerical_features])\n    else:\n        df[numerical_features] = scaler.fit_transform(df[numerical_features])\n\n    categorical_features = df.select_dtypes(exclude=np.number).columns.tolist()\n\n    if test_set:\n        encoded_features = onehot.transform(df[categorical_features])\n    else:\n        encoded_features = onehot.fit_transform(df[categorical_features])\n\n    # get names of new onehot columns, drop existing columns and replace with onehot columns\n    new_cols = onehot.get_feature_names_out()\n\n    encoded_df = pd.DataFrame(encoded_features, columns=new_cols, index=df.index)\n    \n    df = df.drop(columns=categorical_features)\n    df = pd.concat([df, encoded_df], axis=1)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:56.283097Z","iopub.execute_input":"2026-01-17T16:35:56.283535Z","iopub.status.idle":"2026-01-17T16:35:56.291084Z","shell.execute_reply.started":"2026-01-17T16:35:56.283511Z","shell.execute_reply":"2026-01-17T16:35:56.290279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_csv = Path(input_dir) / 'train.csv'\ndf_train = pd.read_csv(train_csv)\n\nX_train, X_valid, y_train, y_valid = train_test_split(df_train, df_train[target], test_size=0.2, random_state=42)\n\nprint(X_train.shape, X_valid.shape)\n\nX_train = prepare(X_train)\nX_valid = prepare(X_valid, test_set=True) # test_set=True for validation so we don't leak scaler info into validation set\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_valid shape: {X_valid.shape}')\nprint(f'y_valid shape: {y_valid.shape}')\nX_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:56.291793Z","iopub.execute_input":"2026-01-17T16:35:56.292007Z","iopub.status.idle":"2026-01-17T16:35:56.418087Z","shell.execute_reply.started":"2026-01-17T16:35:56.29199Z","shell.execute_reply":"2026-01-17T16:35:56.417388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# unsqueeze(1) inserts a new axis at index 1. y_train shape (712,) -> (712, 1)\n# y_train becomes a column vector after unsqueeze, column vectors are needed for output layer of our custom MLP (inference): nn.Linear(64, 1)\nX_train = torch.tensor(X_train.values, dtype=torch.float32)\ny_train = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\nX_valid = torch.tensor(X_valid.values, dtype=torch.float32)\ny_valid = torch.tensor(y_valid.values, dtype=torch.float32).unsqueeze(1)\n\ntrain_ds = TensorDataset(X_train, y_train)\nvalid_ds = TensorDataset(X_valid, y_valid)\n\nbatch_size = 64\n\npin_memory = True if 'cuda' in device else False\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=pin_memory) # pin_memory speeds up data transfer from CPU to GPU\nvalid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, pin_memory=pin_memory) # we don't shuffle test/valid sets for reproducibility reasons","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:56.418779Z","iopub.execute_input":"2026-01-17T16:35:56.419112Z","iopub.status.idle":"2026-01-17T16:35:56.463754Z","shell.execute_reply.started":"2026-01-17T16:35:56.419089Z","shell.execute_reply":"2026-01-17T16:35:56.463084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, 64),\n            nn.LeakyReLU(0.1),\n            nn.Linear(64, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:56.464702Z","iopub.execute_input":"2026-01-17T16:35:56.465362Z","iopub.status.idle":"2026-01-17T16:35:56.470173Z","shell.execute_reply.started":"2026-01-17T16:35:56.465332Z","shell.execute_reply":"2026-01-17T16:35:56.469288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"net = CustomMLP(X_train.shape[1]) # initialize with X_train input dimension","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:56.470939Z","iopub.execute_input":"2026-01-17T16:35:56.47124Z","iopub.status.idle":"2026-01-17T16:35:56.490982Z","shell.execute_reply.started":"2026-01-17T16:35:56.47122Z","shell.execute_reply":"2026-01-17T16:35:56.490358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(net, dataloader, num_epochs, lr, lr_period, lr_decay, momentum, device):\n    net = net.to(device)\n\n    loss = nn.BCELoss()\n    optim = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n\n    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=lr_period, gamma=lr_decay)\n    \n    for epoch in range(num_epochs):\n        net.train()\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            optim.zero_grad()\n            preds = net(X)\n            l = loss(preds, y)\n            l.backward()\n            optim.step()\n        scheduler.step()\n        if (epoch+1) % 5 == 0:\n            print(f'Epoch {epoch + 1} Loss: {l.item():.6f}')       ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:56.493358Z","iopub.execute_input":"2026-01-17T16:35:56.493982Z","iopub.status.idle":"2026-01-17T16:35:56.49959Z","shell.execute_reply.started":"2026-01-17T16:35:56.493959Z","shell.execute_reply":"2026-01-17T16:35:56.498762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train(\n    net,\n    train_loader,\n    num_epochs=100,\n    lr=0.1,\n    momentum=0.9,\n    device=device,\n    lr_period=5,\n    lr_decay=0.99\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:35:56.500322Z","iopub.execute_input":"2026-01-17T16:35:56.500583Z","iopub.status.idle":"2026-01-17T16:36:03.025747Z","shell.execute_reply.started":"2026-01-17T16:35:56.500564Z","shell.execute_reply":"2026-01-17T16:36:03.024926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_acc(net, dataloader, device):\n    net.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            preds_raw = net(X)\n            preds = (preds_raw > 0.5).float() # convert probabilities to prediction, 0 or 1\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n\n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:36:03.02664Z","iopub.execute_input":"2026-01-17T16:36:03.027056Z","iopub.status.idle":"2026-01-17T16:36:03.032206Z","shell.execute_reply.started":"2026-01-17T16:36:03.027013Z","shell.execute_reply":"2026-01-17T16:36:03.031434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = eval_acc(net, valid_loader, device)\nprint(f'Validation accuracy: {acc:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:36:03.032979Z","iopub.execute_input":"2026-01-17T16:36:03.033236Z","iopub.status.idle":"2026-01-17T16:36:03.054009Z","shell.execute_reply.started":"2026-01-17T16:36:03.033218Z","shell.execute_reply":"2026-01-17T16:36:03.053151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_full = prepare(df_train)\ny_train_full = df_train[target]\n\nX_train_full = torch.tensor(X_train_full.values, dtype=torch.float32)\ny_train_full = torch.tensor(y_train_full.values, dtype=torch.float32).unsqueeze(1)\n\nfull_trainset = TensorDataset(X_train_full, y_train_full)\nfull_loader = DataLoader(\n    full_trainset,\n    batch_size=batch_size,\n    shuffle=True,\n    pin_memory=True\n)\n\nnet = CustomMLP(X_train_full.shape[1]) # recreate model to reset pretrained weights and use X_train_full input dimension\n\ntrain(\n    net,\n    full_loader,\n    num_epochs=100,\n    lr=0.1,\n    momentum=0.9,\n    device=device,\n    lr_period=5,\n    lr_decay=0.99\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T16:36:03.054807Z","iopub.execute_input":"2026-01-17T16:36:03.055048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_csv = Path(input_dir) / 'test.csv'\ndf_test = pd.read_csv(test_csv)\n\nX_test = prepare(df_test, test_set=True)\n\nX_test = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n\nwith torch.no_grad():\n    preds = net(X_test)\n    preds = (preds > 0.5).int().squeeze().cpu().numpy()\n\npassenger_ids = df_test['PassengerId']\n\nsubmission = pd.DataFrame({\n    'PassengerId': passenger_ids,\n    'Survived': preds\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}