{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"02896ed2-27d8-4480-b2d8-9f2b6adfd688","cell_type":"markdown","source":"# Titanic â€” CV v3 (Pipeline + OHE + Ensemble, Dense-safe)\n\nWrites `/kaggle/working/submission.csv`\n","metadata":{}},{"id":"d17083ad-e717-458b-98a4-600dfdc9e077","cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, log_loss\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nimport lightgbm as lgb\n\nSEED = 42\nN_SPLITS = 10\n\nTRAIN_PATH = \"/kaggle/input/titanic/train.csv\"\nTEST_PATH  = \"/kaggle/input/titanic/test.csv\"\nWORKDIR = \"/kaggle/working\"\n\nrng = np.random.default_rng(SEED)\nnp.random.seed(SEED)\npd.set_option(\"display.max_columns\", 200)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"41960084-7f51-4813-9bc8-4c7cfa399824","cell_type":"code","source":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\ntrain.shape, test.shape\n","metadata":{},"outputs":[],"execution_count":null},{"id":"de0e9059-2a6f-4352-b038-d91a68074fe8","cell_type":"code","source":"def add_features(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n\n    df[\"Pclass\"] = df[\"Pclass\"].astype(str)\n\n    title = df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n    title = title.replace({\n        \"Mlle\": \"Miss\",\n        \"Ms\": \"Miss\",\n        \"Mme\": \"Mrs\",\n        \"Lady\": \"Rare\",\n        \"Countess\": \"Rare\",\n        \"Capt\": \"Rare\",\n        \"Col\": \"Rare\",\n        \"Don\": \"Rare\",\n        \"Dr\": \"Rare\",\n        \"Major\": \"Rare\",\n        \"Rev\": \"Rare\",\n        \"Sir\": \"Rare\",\n        \"Jonkheer\": \"Rare\",\n        \"Dona\": \"Rare\",\n    })\n    df[\"Title\"] = title.fillna(\"Rare\")\n\n    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n    df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n\n    df[\"CabinKnown\"] = df[\"Cabin\"].notna().astype(int)\n    df[\"Deck\"] = df[\"Cabin\"].astype(str).str[0].replace(\"n\", np.nan).fillna(\"U\")\n\n    ticket_prefix = (\n        df[\"Ticket\"]\n        .astype(str)\n        .str.replace(r\"\\d+\", \"\", regex=True)\n        .str.replace(r\"\\s+\", \"\", regex=True)\n        .str.strip()\n    )\n    df[\"TicketPrefix\"] = ticket_prefix.replace(\"\", \"NUM\")\n\n    df[\"FareLog\"] = np.log1p(df[\"Fare\"])\n\n    df[\"NameLen\"] = df[\"Name\"].astype(str).str.len()\n    df[\"SexPclass\"] = df[\"Sex\"].astype(str) + \"_\" + df[\"Pclass\"].astype(str)\n\n    df[\"IsChild\"] = (df[\"Age\"] <= 14).astype(int)\n\n    return df\n\ntrain_fe = add_features(train)\ntest_fe  = add_features(test)\n\ny = train_fe[\"Survived\"].astype(int).to_numpy()\n\ndrop_cols = [\"Survived\", \"Name\", \"Ticket\", \"Cabin\"]\nX = train_fe.drop(columns=drop_cols)\nX_test = test_fe.drop(columns=[c for c in drop_cols if c != \"Survived\"])\n\nX.shape, X_test.shape\n","metadata":{},"outputs":[],"execution_count":null},{"id":"f307414a-fa31-4456-a738-c9cc6822c283","cell_type":"code","source":"cat_cols = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\", \"Deck\", \"TicketPrefix\", \"SexPclass\"]\nnum_cols = [c for c in X.columns if c not in cat_cols]\n\nfor c in cat_cols:\n    X[c] = X[c].astype(\"object\")\n    X_test[c] = X_test[c].astype(\"object\")\n\npre = ColumnTransformer(\n    transformers=[\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n                          (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n    ],\n    remainder=\"drop\"\n)\n\npre\n","metadata":{},"outputs":[],"execution_count":null},{"id":"18853965-e51b-4728-b0f8-5f063680ee51","cell_type":"code","source":"class DenseTransformer:\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n\ndef make_pipeline(model, needs_dense=False):\n    if needs_dense:\n        return Pipeline([(\"pre\", pre), (\"dense\", DenseTransformer()), (\"model\", model)])\n    return Pipeline([(\"pre\", pre), (\"model\", model)])\n\ndef oof_predict_proba(model, X_all, y_all, X_te, needs_dense=False):\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n    oof = np.zeros(len(X_all), dtype=float)\n    te = np.zeros(len(X_te), dtype=float)\n\n    for trn, val in skf.split(X_all, y_all):\n        X_tr, X_va = X_all.iloc[trn], X_all.iloc[val]\n        y_tr, y_va = y_all[trn], y_all[val]\n\n        clf = make_pipeline(model, needs_dense=needs_dense)\n        clf.fit(X_tr, y_tr)\n\n        oof[val] = clf.predict_proba(X_va)[:, 1]\n        te += clf.predict_proba(X_te)[:, 1] / N_SPLITS\n\n    return oof, te\n\ndef tune_threshold(y_true, proba):\n    ths = np.linspace(0.05, 0.95, 181)\n    best_t = 0.5\n    best_a = -1.0\n    for t in ths:\n        a = accuracy_score(y_true, (proba >= t).astype(int))\n        if a > best_a:\n            best_a = a\n            best_t = float(t)\n    return best_t, float(best_a)\n\ndef safe_logloss(y_true, proba):\n    p = np.clip(proba, 1e-6, 1 - 1e-6)\n    return float(log_loss(y_true, p))\n","metadata":{},"outputs":[],"execution_count":null},{"id":"ea44223b-ef70-4673-b9af-4707b8a6c9f9","cell_type":"code","source":"m_lr = LogisticRegression(\n    C=2.0,\n    solver=\"liblinear\",\n    max_iter=2000,\n    random_state=SEED\n)\n\nm_hgb = HistGradientBoostingClassifier(\n    max_depth=6,\n    learning_rate=0.05,\n    max_iter=800,\n    random_state=SEED\n)\n\nm_lgb = lgb.LGBMClassifier(\n    n_estimators=5000,\n    learning_rate=0.02,\n    num_leaves=64,\n    max_depth=-1,\n    min_child_samples=20,\n    subsample=0.85,\n    colsample_bytree=0.85,\n    reg_lambda=1.0,\n    random_state=SEED,\n    n_jobs=-1\n)\n\noof_lr, te_lr = oof_predict_proba(m_lr, X, y, X_test, needs_dense=False)\noof_hgb, te_hgb = oof_predict_proba(m_hgb, X, y, X_test, needs_dense=True)\noof_lgb, te_lgb = oof_predict_proba(m_lgb, X, y, X_test, needs_dense=False)\n\nscores = {\n    \"lr\":  {\"acc\": tune_threshold(y, oof_lr)[1],  \"t\": tune_threshold(y, oof_lr)[0],  \"logloss\": safe_logloss(y, oof_lr)},\n    \"hgb\": {\"acc\": tune_threshold(y, oof_hgb)[1], \"t\": tune_threshold(y, oof_hgb)[0], \"logloss\": safe_logloss(y, oof_hgb)},\n    \"lgb\": {\"acc\": tune_threshold(y, oof_lgb)[1], \"t\": tune_threshold(y, oof_lgb)[0], \"logloss\": safe_logloss(y, oof_lgb)},\n}\n\nscores\n","metadata":{},"outputs":[],"execution_count":null},{"id":"ffae0fc6-2525-48d2-bfca-6df8199b71ce","cell_type":"code","source":"P = np.column_stack([oof_lr, oof_hgb, oof_lgb])\nT = np.column_stack([te_lr, te_hgb, te_lgb])\n\nbest_w = np.ones(3) / 3\nbest_s = safe_logloss(y, P @ best_w)\n\nfor _ in range(15000):\n    w = rng.dirichlet(np.ones(3))\n    s = safe_logloss(y, P @ w)\n    if s < best_s:\n        best_s = s\n        best_w = w\n\nstep = 0.05\nfor _ in range(6000):\n    i = int(rng.integers(0, 3))\n    j = int(rng.integers(0, 3))\n    if i == j:\n        continue\n    w = best_w.copy()\n    delta = float(rng.uniform(-step, step))\n    w[i] = max(0.0, w[i] + delta)\n    w[j] = max(0.0, w[j] - delta)\n    ssum = w.sum()\n    if ssum <= 0:\n        continue\n    w /= ssum\n    s = safe_logloss(y, P @ w)\n    if s < best_s:\n        best_s = s\n        best_w = w\n\nblend_oof = P @ best_w\nblend_test = T @ best_w\n\nt_blend, a_blend = tune_threshold(y, blend_oof)\nbest_w, best_s, a_blend, t_blend\n","metadata":{},"outputs":[],"execution_count":null},{"id":"6b5e2cc2-84cf-4768-985f-41248563b3b9","cell_type":"code","source":"pred_test = (blend_test >= t_blend).astype(int)\n\nsubmission = pd.DataFrame({\n    \"PassengerId\": test[\"PassengerId\"].values,\n    \"Survived\": pred_test\n})\n\nout_path = f\"{WORKDIR}/submission.csv\"\nsubmission.to_csv(out_path, index=False)\n\nout_path\n","metadata":{},"outputs":[],"execution_count":null}]}