{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119106,"databundleVersionId":14485445,"sourceType":"competition"},{"sourceId":290968378,"sourceType":"kernelVersion"},{"sourceId":291700304,"sourceType":"kernelVersion"},{"sourceId":291758261,"sourceType":"kernelVersion"},{"sourceId":291786619,"sourceType":"kernelVersion"},{"sourceId":291829329,"sourceType":"kernelVersion"},{"sourceId":291829419,"sourceType":"kernelVersion"},{"sourceId":291912043,"sourceType":"kernelVersion"},{"sourceId":291940908,"sourceType":"kernelVersion"},{"sourceId":292023051,"sourceType":"kernelVersion"},{"sourceId":292208418,"sourceType":"kernelVersion"},{"sourceId":292245163,"sourceType":"kernelVersion"},{"sourceId":292408374,"sourceType":"kernelVersion"},{"sourceId":292445618,"sourceType":"kernelVersion"},{"sourceId":292451548,"sourceType":"kernelVersion"},{"sourceId":292514207,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import subprocess\nimport shutil\nimport os\nimport time\nimport math\nimport pandas as pd\nimport numpy as np\nfrom numba import njit\nfrom decimal import Decimal, getcontext\nfrom shapely import affinity\nfrom shapely.geometry import Polygon\nfrom shapely.strtree import STRtree\nimport random\nfrom collections import defaultdict\n\n# ============================================================\n# CONFIGURATION\n# ============================================================\nMAX_TIME_SECONDS = 10 * 60\nBBOX3_TIMEOUT = 150\nSA_ITERATIONS = 125\nGRADIENT_STEPS = 20\nBASIN_HOP_PERTURBATION = 0.04\n\n# --- Setup Paths ---\nINPUT_SUB = '/kaggle/input/santa-submission/submission.csv'\nINPUT_BIN = '/kaggle/input/santa-submission/bbox3'\nWORKING_DIR = '/kaggle/working/'\n\nprint(\"üìÇ Setting up environment...\")\n\nif os.path.exists(INPUT_SUB):\n    shutil.copy(INPUT_SUB, os.path.join(WORKING_DIR, 'submission.csv'))\n    print(f\"‚úÖ Copied submission.csv\")\n\nif os.path.exists(INPUT_BIN):\n    shutil.copy(INPUT_BIN, os.path.join(WORKING_DIR, 'bbox3'))\n    os.chmod('./bbox3', 0o755)\n    print(f\"‚úÖ Copied and set permissions for bbox3\")\n\ngetcontext().prec = 25\nscale_factor = Decimal(\"1e18\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T01:46:53.057007Z","iopub.execute_input":"2026-01-18T01:46:53.057235Z","iopub.status.idle":"2026-01-18T01:46:57.429563Z","shell.execute_reply.started":"2026-01-18T01:46:53.057215Z","shell.execute_reply":"2026-01-18T01:46:57.428442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"code","source":"%%writefile ensemble_submissions.py\n#!/usr/bin/env python3\n\"\"\"\nEnsemble Optimizer\n\"\"\"\n\nimport csv\nimport math\nimport glob\nimport os\nfrom collections import defaultdict\nfrom typing import Dict, List, Tuple\n\n# Tree shape constants (from C++ code)\nTX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\nTY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n\ndef get_polygon_bounds(cx: float, cy: float, deg: float) -> Tuple[float, float, float, float]:\n    \"\"\"Calculate bounding box of rotated tree polygon\"\"\"\n    rad = deg * math.pi / 180.0\n    s = math.sin(rad)\n    c = math.cos(rad)\n    \n    x_coords = []\n    y_coords = []\n    \n    for i in range(len(TX)):\n        x = TX[i] * c - TY[i] * s + cx\n        y = TX[i] * s + TY[i] * c + cy\n        x_coords.append(x)\n        y_coords.append(y)\n    \n    return min(x_coords), max(x_coords), min(y_coords), max(y_coords)\n\ndef calculate_score(trees: List[Tuple[int, float, float, float]]) -> Tuple[float, float, float, float]:\n    \"\"\"\n    Calculate score for a configuration\n    Returns: (score, side, width, height)\n    \"\"\"\n    if not trees:\n        return float('inf'), 0, 0, 0\n    \n    global_x_min = float('inf')\n    global_x_max = float('-inf')\n    global_y_min = float('inf')\n    global_y_max = float('-inf')\n    \n    for idx, cx, cy, deg in trees:\n        x_min, x_max, y_min, y_max = get_polygon_bounds(cx, cy, deg)\n        global_x_min = min(global_x_min, x_min)\n        global_x_max = max(global_x_max, x_max)\n        global_y_min = min(global_y_min, y_min)\n        global_y_max = max(global_y_max, y_max)\n    \n    width = global_x_max - global_x_min\n    height = global_y_max - global_y_min\n    side = max(width, height)\n    score = side * side / len(trees)\n    \n    return score, side, width, height\n\ndef load_submission(filepath: str) -> Dict[int, List[Tuple[int, float, float, float]]]:\n    \"\"\"\n    Load submission file\n    Returns: dict mapping n -> list of (idx, x, y, deg)\n    \"\"\"\n    configurations = defaultdict(list)\n    \n    try:\n        with open(filepath, 'r') as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                # Parse id\n                id_parts = row['id'].split('_')\n                n = int(id_parts[0])\n                idx = int(id_parts[1])\n                \n                # Parse coordinates (remove 's' prefix if present)\n                x = float(row['x'].replace('s', ''))\n                y = float(row['y'].replace('s', ''))\n                deg = float(row['deg'].replace('s', ''))\n                \n                configurations[n].append((idx, x, y, deg))\n        \n        # Sort by index\n        for n in configurations:\n            configurations[n].sort(key=lambda t: t[0])\n        \n        return dict(configurations)\n    \n    except Exception as e:\n        print(f\"Error loading {filepath}: {e}\")\n        return {}\n\ndef analyze_submission(filepath: str, configurations: Dict[int, List]) -> Dict[int, Tuple]:\n    \"\"\"\n    Analyze a submission file\n    Returns: dict mapping n -> (score, side, width, height)\n    \"\"\"\n    results = {}\n    \n    for n, trees in configurations.items():\n        if len(trees) != n:\n            print(f\"  WARNING: n={n} has {len(trees)} trees (expected {n})\")\n            continue\n        \n        score, side, width, height = calculate_score(trees)\n        results[n] = (score, side, width, height)\n    \n    return results\n\ndef create_ensemble(submissions: Dict[str, Dict[int, List]]) -> Dict[int, Tuple[List, str, float]]:\n    \"\"\"\n    Create ensemble by selecting best configuration for each n\n    Returns: dict mapping n -> (best_trees, source_file, score)\n    \"\"\"\n    ensemble = {}\n    \n    # Get all n values\n    all_n = set()\n    for configs in submissions.values():\n        all_n.update(configs.keys())\n    \n    # For each n, find best configuration\n    for n in sorted(all_n):\n        best_score = float('inf')\n        best_trees = None\n        best_source = None\n        \n        for filepath, configs in submissions.items():\n            if n not in configs:\n                continue\n            \n            trees = configs[n]\n            if len(trees) != n:\n                continue\n            \n            score, side, width, height = calculate_score(trees)\n            \n            if score < best_score:\n                best_score = score\n                best_trees = trees\n                best_source = filepath\n        \n        if best_trees:\n            ensemble[n] = (best_trees, best_source, best_score)\n    \n    return ensemble\n\ndef save_ensemble(ensemble: Dict[int, Tuple], output_path: str):\n    \"\"\"Save ensemble submission\"\"\"\n    with open(output_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['id', 'x', 'y', 'deg'])\n        \n        for n in sorted(ensemble.keys()):\n            trees, _, _ = ensemble[n]\n            for idx, x, y, deg in trees:\n                row_id = f\"{n:03d}_{idx}\"\n                writer.writerow([row_id, f's{x:.17f}', f's{y:.17f}', f's{deg:.17f}'])\n\ndef print_comparison(submissions: Dict[str, Dict[int, List]], ensemble: Dict[int, Tuple]):\n    \"\"\"Print detailed comparison\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"DETAILED COMPARISON BY N\")\n    print(\"=\"*80)\n    \n    all_n = sorted(set(\n        n for configs in submissions.values() \n        for n in configs.keys()\n    ))\n    \n    # Prepare data for each n\n    for n in all_n:\n        print(f\"\\n{'‚îÄ'*80}\")\n        print(f\"n = {n}\")\n        print(f\"{'‚îÄ'*80}\")\n        \n        # Collect scores from all submissions\n        scores_data = []\n        for filepath, configs in submissions.items():\n            if n in configs and len(configs[n]) == n:\n                score, side, width, height = calculate_score(configs[n])\n                basename = os.path.basename(filepath)\n                scores_data.append((basename, score, side))\n        \n        # Sort by score\n        scores_data.sort(key=lambda x: x[1])\n        \n        # Print table\n        print(f\"{'Source':<30} {'Score':<20} {'Side':<20} {'Status'}\")\n        print(f\"{'-'*30} {'-'*20} {'-'*20} {'-'*10}\")\n        \n        for i, (source, score, side) in enumerate(scores_data):\n            status = \"‚úÖ BEST\" if i == 0 else \"\"\n            print(f\"{source:<30} {score:<20.15f} {side:<20.15f} {status}\")\n        \n        # Show ensemble choice\n        if n in ensemble:\n            _, best_source, best_score = ensemble[n]\n            print(f\"\\n‚Üí Ensemble choice: {os.path.basename(best_source)} (score: {best_score:.15f})\")\n        \n        # Calculate improvement range\n        if len(scores_data) > 1:\n            worst_score = scores_data[-1][1]\n            best_score = scores_data[0][1]\n            improvement = (worst_score - best_score) / worst_score * 100\n            print(f\"‚Üí Improvement range: {improvement:.4f}%\")\n\ndef print_summary(submissions: Dict[str, Dict[int, List]], ensemble: Dict[int, Tuple]):\n    \"\"\"Print summary statistics\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY STATISTICS\")\n    print(\"=\"*80)\n    \n    # Per-file statistics\n    print(\"\\nPer-file statistics:\")\n    print(f\"{'File':<30} {'Total n':<10} {'Avg Score':<20} {'Best Count'}\")\n    print(f\"{'-'*30} {'-'*10} {'-'*20} {'-'*10}\")\n    \n    for filepath, configs in sorted(submissions.items()):\n        basename = os.path.basename(filepath)\n        \n        # Calculate average score\n        total_score = 0\n        count = 0\n        for n, trees in configs.items():\n            if len(trees) == n:\n                score, _, _, _ = calculate_score(trees)\n                total_score += score\n                count += 1\n        \n        avg_score = total_score / count if count > 0 else 0\n        \n        # Count how many times this file was chosen as best\n        best_count = sum(1 for _, source, _ in ensemble.values() \n                        if source == filepath)\n        \n        print(f\"{basename:<30} {count:<10} {avg_score:<20.10f} {best_count}\")\n    \n    # Ensemble statistics\n    print(\"\\n\" + \"-\"*80)\n    print(\"Ensemble statistics:\")\n    \n    total_score = sum(score for _, _, score in ensemble.values())\n    avg_score = total_score / len(ensemble) if ensemble else 0\n\n   \n    print(f\"  Total n values: {len(ensemble)}\")\n    print(f\"  Total score: {total_score}\")\n    print(f\"  Average score:  {avg_score:.10f}\")\n    \n    # Count improvements\n    print(\"\\nSource distribution in ensemble:\")\n    source_counts = defaultdict(int)\n    for _, source, _ in ensemble.values():\n        basename = os.path.basename(source)\n        source_counts[basename] += 1\n    \n    for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n        pct = count / len(ensemble) * 100\n        print(f\"  {source:<30} {count:>3} / {len(ensemble)} ({pct:>5.1f}%)\")\n\ndef print_highlights(ensemble: Dict[int, Tuple]):\n    \"\"\"Print highlights - best and worst scores\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"HIGHLIGHTS\")\n    print(\"=\"*80)\n    \n    # Sort by score\n    sorted_n = sorted(ensemble.items(), key=lambda x: x[1][2])\n    \n    print(\"\\nüèÜ TOP 10 BEST SCORES:\")\n    print(f\"{'n':<5} {'Score':<20} {'Source'}\")\n    print(f\"{'-'*5} {'-'*20} {'-'*40}\")\n    for i, (n, (_, source, score)) in enumerate(sorted_n[:10]):\n        basename = os.path.basename(source)\n        print(f\"{n:<5} {score:<20.15f} {basename}\")\n    \n    print(\"\\n‚ö†Ô∏è  TOP 10 WORST SCORES:\")\n    print(f\"{'n':<5} {'Score':<20} {'Source'}\")\n    print(f\"{'-'*5} {'-'*20} {'-'*40}\")\n    for i, (n, (_, source, score)) in enumerate(sorted_n[-10:]):\n        basename = os.path.basename(source)\n        print(f\"{n:<5} {score:<20.15f} {basename}\")\n\ndef main():\n    import argparse\n    \n    parser = argparse.ArgumentParser(description='Ensemble multiple submissions')\n    parser.add_argument('-d', '--dir', default='submissions', \n                       help='Directory containing submission files')\n    parser.add_argument('-o', '--output', default='submission_ensemble.csv',\n                       help='Output ensemble file')\n    parser.add_argument('--verbose', action='store_true',\n                       help='Show detailed comparison')\n    \n    args = parser.parse_args()    \n    # Find all CSV files\n    csv_files = glob.glob(os.path.join(args.dir, '*.csv'))\n    \n    if not csv_files:\n        print(f\"‚ùå No CSV files found in {args.dir}\")\n        return\n    \n    print(f\"üìÅ Found {len(csv_files)} submission files:\")\n    for f in csv_files:\n        size = os.path.getsize(f) / 1024\n        print(f\"   - {os.path.basename(f):<30} ({size:>8.1f} KB)\")\n    \n    # Load all submissions\n    print(f\"\\nüìä Loading submissions...\")\n    submissions = {}\n    for filepath in csv_files:\n        basename = os.path.basename(filepath)\n        print(f\"   Loading {basename}...\", end=' ')\n        configs = load_submission(filepath)\n        if configs:\n            submissions[filepath] = configs\n            print(f\"‚úÖ ({len(configs)} groups)\")\n        else:\n            print(\"‚ùå Failed\")\n    \n    if not submissions:\n        print(\"\\n‚ùå No valid submissions loaded\")\n        return\n    \n    print(f\"\\n‚úÖ Loaded {len(submissions)} submissions successfully\")\n    \n    # Create ensemble\n    print(f\"\\nüîß Creating ensemble (selecting best for each n)...\")\n    ensemble = create_ensemble(submissions)\n    \n    print(f\"‚úÖ Ensemble created with {len(ensemble)} groups\")\n    \n    # Save ensemble\n    print(f\"\\nüíæ Saving to {args.output}...\")\n    save_ensemble(ensemble, args.output)\n    print(f\"‚úÖ Saved!\")\n    \n    # Print statistics\n    print_summary(submissions, ensemble)\n    print_highlights(ensemble)\n    \n    if args.verbose:\n        print_comparison(submissions, ensemble)\n    else:\n        print(\"\\nüí° Use --verbose flag to see detailed comparison for each n\")\n    \n    # Final summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"‚úÖ ENSEMBLE COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"\\nüìÑ Output: {args.output}\")\n    print(f\"üìä Total groups: {len(ensemble)}\")\n    \n    # Calculate overall improvement\n    total_improvement = 0\n    count = 0\n    for n in ensemble.keys():\n        scores = []\n        for filepath, configs in submissions.items():\n            if n in configs and len(configs[n]) == n:\n                score, _, _, _ = calculate_score(configs[n])\n                scores.append(score)\n        \n        if len(scores) > 1:\n            best = min(scores)\n            worst = max(scores)\n            if worst > 0:\n                improvement = (worst - best) / worst * 100\n                total_improvement += improvement\n                count += 1\n    \n    if count > 0:\n        avg_improvement = total_improvement / count\n        print(f\"üìà Average improvement per group: {avg_improvement:.4f}%\")\n    \n    print(\"\\nüéØ Next steps:\")\n    print(f\"Review the ensemble: {args.output}\")\n    print()\n\nif __name__ == '__main__':\n    main()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T02:11:50.226594Z","iopub.execute_input":"2026-01-18T02:11:50.226975Z","iopub.status.idle":"2026-01-18T02:11:50.242717Z","shell.execute_reply.started":"2026-01-18T02:11:50.226945Z","shell.execute_reply":"2026-01-18T02:11:50.241554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport shutil\n\n\ntemp_dir = f\"temp_merge\"\nif os.path.exists(temp_dir):\n    os.system(\"rm -rf \" + temp_dir)\nos.makedirs(temp_dir, exist_ok=True)\n\nall_files = glob.glob(f\"/kaggle/input/*/*.csv\")\nfor i, file in enumerate(all_files):\n    new_file = os.path.join(temp_dir, f\"submission_{i+1}.csv\")\n    shutil.copy(file, new_file)\n    print(f\"Copied {i+1} files\")\n\nprint(f\"Number of files: {len(all_files)}\")\n\n!python3 ./ensemble_submissions.py -d {temp_dir} -o /kaggle/working/submission_ensemble.csv\n!cp /kaggle/working/submission_ensemble.csv   /kaggle/working/submission.csv\n!rm -rf temp_merge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T02:11:52.766199Z","iopub.execute_input":"2026-01-18T02:11:52.766545Z","iopub.status.idle":"2026-01-18T02:12:07.75944Z","shell.execute_reply.started":"2026-01-18T02:11:52.766519Z","shell.execute_reply":"2026-01-18T02:12:07.758231Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimized","metadata":{"execution":{"iopub.status.busy":"2026-01-18T02:04:26.213497Z","iopub.execute_input":"2026-01-18T02:04:26.213955Z","iopub.status.idle":"2026-01-18T02:04:26.218555Z","shell.execute_reply.started":"2026-01-18T02:04:26.213927Z","shell.execute_reply":"2026-01-18T02:04:26.217593Z"}}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CORE FUNCTIONS - Numba optimized\n# ============================================================\n\n@njit(cache=True)\ndef make_polygon_template():\n    tw=0.15; th=0.2; bw=0.7; mw=0.4; ow=0.25\n    tip=0.8; t1=0.5; t2=0.25; base=0.0; tbot=-th\n    x = np.array([0,ow/2,ow/4,mw/2,mw/4,bw/2,tw/2,tw/2,-tw/2,-tw/2,-bw/2,-mw/4,-mw/2,-ow/4,-ow/2], np.float64)\n    y = np.array([tip,t1,t1,t2,t2,base,base,tbot,tbot,base,base,t2,t2,t1,t1], np.float64)\n    return x, y\n\n@njit(cache=True)\ndef score_group_fast(xs, ys, degs, tx, ty):\n    n = xs.size\n    V = tx.size\n    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n    for i in range(n):\n        r = degs[i] * math.pi / 180.0\n        c = math.cos(r); s = math.sin(r)\n        xi = xs[i]; yi = ys[i]\n        for j in range(V):\n            X = c*tx[j] - s*ty[j] + xi\n            Y = s*tx[j] + c*ty[j] + yi\n            if X < mnx: mnx = X\n            if X > mxx: mxx = X\n            if Y < mny: mny = Y\n            if Y > mxy: mxy = Y\n    side = max(mxx - mnx, mxy - mny)\n    return side * side / n\n\n@njit(cache=True)\ndef get_bounding_box(xs, ys, degs, tx, ty):\n    n = xs.size\n    V = tx.size\n    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n    for i in range(n):\n        r = degs[i] * math.pi / 180.0\n        c = math.cos(r); s = math.sin(r)\n        xi = xs[i]; yi = ys[i]\n        for j in range(V):\n            X = c*tx[j] - s*ty[j] + xi\n            Y = s*tx[j] + c*ty[j] + yi\n            if X < mnx: mnx = X\n            if X > mxx: mxx = X\n            if Y < mny: mny = Y\n            if Y > mxy: mxy = Y\n    return mnx, mny, mxx, mxy\n\n@njit(cache=True)\ndef find_boundary_trees(xs, ys, degs, tx, ty):\n    n = xs.size\n    V = tx.size\n    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n    min_x_tree = 0; min_y_tree = 0; max_x_tree = 0; max_y_tree = 0\n    \n    for i in range(n):\n        r = degs[i] * math.pi / 180.0\n        c = math.cos(r); s = math.sin(r)\n        xi = xs[i]; yi = ys[i]\n        for j in range(V):\n            X = c*tx[j] - s*ty[j] + xi\n            Y = s*tx[j] + c*ty[j] + yi\n            if X < mnx: mnx = X; min_x_tree = i\n            if X > mxx: mxx = X; max_x_tree = i\n            if Y < mny: mny = Y; min_y_tree = i\n            if Y > mxy: mxy = Y; max_y_tree = i\n    \n    return min_x_tree, min_y_tree, max_x_tree, max_y_tree","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# SHAPELY-BASED OVERLAP CHECKING (CRITICAL!)\n# ============================================================\n\nclass ChristmasTree:\n    def __init__(self, center_x=\"0\", center_y=\"0\", angle=\"0\"):\n        self.center_x = Decimal(str(center_x))\n        self.center_y = Decimal(str(center_y))\n        self.angle = Decimal(str(angle))\n        \n        trunk_w = Decimal(\"0.15\")\n        trunk_h = Decimal(\"0.2\")\n        base_w = Decimal(\"0.7\")\n        mid_w = Decimal(\"0.4\")\n        top_w = Decimal(\"0.25\")\n        tip_y = Decimal(\"0.8\")\n        tier_1_y = Decimal(\"0.5\")\n        tier_2_y = Decimal(\"0.25\")\n        base_y = Decimal(\"0.0\")\n        trunk_bottom_y = -trunk_h\n\n        initial_polygon = Polygon([\n            (Decimal(\"0.0\") * scale_factor, tip_y * scale_factor),\n            (top_w / Decimal(\"2\") * scale_factor, tier_1_y * scale_factor),\n            (top_w / Decimal(\"4\") * scale_factor, tier_1_y * scale_factor),\n            (mid_w / Decimal(\"2\") * scale_factor, tier_2_y * scale_factor),\n            (mid_w / Decimal(\"4\") * scale_factor, tier_2_y * scale_factor),\n            (base_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n            (trunk_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n            (trunk_w / Decimal(\"2\") * scale_factor, trunk_bottom_y * scale_factor),\n            (-(trunk_w / Decimal(\"2\")) * scale_factor, trunk_bottom_y * scale_factor),\n            (-(trunk_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n            (-(base_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n            (-(mid_w / Decimal(\"4\")) * scale_factor, tier_2_y * scale_factor),\n            (-(mid_w / Decimal(\"2\")) * scale_factor, tier_2_y * scale_factor),\n            (-(top_w / Decimal(\"4\")) * scale_factor, tier_1_y * scale_factor),\n            (-(top_w / Decimal(\"2\")) * scale_factor, tier_1_y * scale_factor),\n        ])\n        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n        self.polygon = affinity.translate(\n            rotated, xoff=float(self.center_x * scale_factor), yoff=float(self.center_y * scale_factor)\n        )\n\ndef create_trees_from_arrays(xs, ys, degs):\n    \"\"\"Create ChristmasTree objects from numpy arrays.\"\"\"\n    return [ChristmasTree(str(xs[i]), str(ys[i]), str(degs[i])) for i in range(len(xs))]\n\ndef has_overlap_arrays(xs, ys, degs):\n    \"\"\"Check if configuration has overlaps using arrays directly.\"\"\"\n    if len(xs) <= 1:\n        return False\n    trees = create_trees_from_arrays(xs, ys, degs)\n    return has_overlap(trees)\n\ndef has_overlap(trees):\n    \"\"\"Check if any trees overlap.\"\"\"\n    if len(trees) <= 1:\n        return False\n    polygons = [t.polygon for t in trees]\n    tree_index = STRtree(polygons)\n    for i, poly in enumerate(polygons):\n        for idx in tree_index.query(poly):\n            if idx != i and poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n                return True\n    return False\n\ndef load_configuration_from_df(n, df):\n    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n    trees = []\n    for _, row in group_data.iterrows():\n        trees.append(ChristmasTree(row[\"x\"][1:], row[\"y\"][1:], row[\"deg\"][1:]))\n    return trees\n\ndef get_score(trees, n=None):\n    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / 1e18 for t in trees])\n    min_x, min_y = xys.min(axis=0)\n    max_x, max_y = xys.max(axis=0)\n    score = max(max_x - min_x, max_y - min_y) ** 2\n    return score / n if n else score\n\ndef eval_df_sub(df, verbose=False):\n    failed = []\n    total_score = 0.0\n    scores = {}\n    for n in range(1, 201):\n        trees = load_configuration_from_df(n, df)\n        score = get_score(trees, n)\n        scores[n] = score\n        total_score += score\n        if verbose:\n            print(f\"{n:3}  {score:.6f}\")\n        if has_overlap(trees):\n            failed.append(n)\n    \n    if not failed:\n        print(\"‚úÖ No overlaps\")\n    else:\n        print(f\"‚ùå Overlaps in: {failed}\")\n    print(f\"üìä Score: {total_score:.12f}\")\n    return total_score, scores","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPROVEMENT 1: Simulated Annealing (WITH OVERLAP CHECK)\n# ============================================================\n\ndef simulated_annealing_config(df, config_n, max_iterations=200, \n                                initial_temp=0.001, cooling_rate=0.995):\n    \"\"\"\n    Simulated annealing with overlap validation.\n    \"\"\"\n    tx, ty = make_polygon_template()\n    \n    group_mask = df[\"id\"].str.startswith(f\"{config_n:03d}_\")\n    group_data = df[group_mask].copy()\n    \n    xs = np.array([float(v[1:]) for v in group_data[\"x\"]])\n    ys = np.array([float(v[1:]) for v in group_data[\"y\"]])\n    degs = np.array([float(v[1:]) for v in group_data[\"deg\"]])\n    \n    n_trees = len(xs)\n    if n_trees <= 1:\n        return False, 0\n    \n    original_score = score_group_fast(xs, ys, degs, tx, ty)\n    current_score = original_score\n    best_score = original_score\n    best_xs, best_ys, best_degs = xs.copy(), ys.copy(), degs.copy()\n    \n    temperature = initial_temp\n    step_xy = 0.002 / np.sqrt(n_trees)\n    step_rot = 0.5 / np.sqrt(n_trees)\n    \n    for iteration in range(max_iterations):\n        tree_idx = random.randint(0, n_trees - 1)\n        \n        new_xs = xs.copy()\n        new_ys = ys.copy()\n        new_degs = degs.copy()\n        \n        move = random.choice(['translate', 'rotate', 'both'])\n        \n        if move in ['translate', 'both']:\n            new_xs[tree_idx] += random.gauss(0, step_xy)\n            new_ys[tree_idx] += random.gauss(0, step_xy)\n        \n        if move in ['rotate', 'both']:\n            new_degs[tree_idx] += random.gauss(0, step_rot)\n        \n        new_score = score_group_fast(new_xs, new_ys, new_degs, tx, ty)\n        delta = new_score - current_score\n        \n        # Only check overlap if we might accept the move\n        if delta < 0 or random.random() < math.exp(-delta / temperature):\n            # CRITICAL: Check for overlaps before accepting!\n            if not has_overlap_arrays(new_xs, new_ys, new_degs):\n                xs, ys, degs = new_xs, new_ys, new_degs\n                current_score = new_score\n                \n                if current_score < best_score:\n                    best_score = current_score\n                    best_xs, best_ys, best_degs = xs.copy(), ys.copy(), degs.copy()\n        \n        temperature *= cooling_rate\n    \n    improved = best_score < original_score - 1e-15\n    \n    if improved:\n        # Final validation before writing\n        if not has_overlap_arrays(best_xs, best_ys, best_degs):\n            indices = df[group_mask].index\n            for i, idx in enumerate(indices):\n                df.at[idx, 'x'] = f\"s{best_xs[i]}\"\n                df.at[idx, 'y'] = f\"s{best_ys[i]}\"\n                df.at[idx, 'deg'] = f\"s{best_degs[i]}\"\n        else:\n            improved = False\n    \n    return improved, original_score - best_score if improved else 0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPROVEMENT 2: Swap-based moves (WITH OVERLAP CHECK)\n# ============================================================\n\ndef try_swap_trees(df, config_n, max_swaps=50):\n    \"\"\"\n    Try swapping positions with overlap validation.\n    \"\"\"\n    tx, ty = make_polygon_template()\n    \n    group_mask = df[\"id\"].str.startswith(f\"{config_n:03d}_\")\n    group_data = df[group_mask].copy()\n    \n    xs = np.array([float(v[1:]) for v in group_data[\"x\"]])\n    ys = np.array([float(v[1:]) for v in group_data[\"y\"]])\n    degs = np.array([float(v[1:]) for v in group_data[\"deg\"]])\n    \n    n_trees = len(xs)\n    if n_trees <= 2:\n        return False, 0\n    \n    original_score = score_group_fast(xs, ys, degs, tx, ty)\n    best_score = original_score\n    best_xs, best_ys = xs.copy(), ys.copy()\n    \n    for _ in range(max_swaps):\n        i, j = random.sample(range(n_trees), 2)\n        \n        new_xs = xs.copy()\n        new_ys = ys.copy()\n        new_xs[i], new_xs[j] = new_xs[j], new_xs[i]\n        new_ys[i], new_ys[j] = new_ys[j], new_ys[i]\n        \n        new_score = score_group_fast(new_xs, new_ys, degs, tx, ty)\n        \n        if new_score < best_score:\n            # CRITICAL: Check overlaps!\n            if not has_overlap_arrays(new_xs, new_ys, degs):\n                best_score = new_score\n                best_xs, best_ys = new_xs.copy(), new_ys.copy()\n                xs, ys = new_xs, new_ys\n    \n    improved = best_score < original_score - 1e-15\n    if improved:\n        if not has_overlap_arrays(best_xs, best_ys, degs):\n            indices = df[group_mask].index\n            for i, idx in enumerate(indices):\n                df.at[idx, 'x'] = f\"s{best_xs[i]}\"\n                df.at[idx, 'y'] = f\"s{best_ys[i]}\"\n        else:\n            improved = False\n    \n    return improved, original_score - best_score if improved else 0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPROVEMENT 3: Boundary tree optimization (WITH OVERLAP CHECK)\n# ============================================================\n\ndef optimize_boundary_trees(df, config_n, iterations=100):\n    \"\"\"\n    Focus on boundary trees with overlap validation.\n    \"\"\"\n    tx, ty = make_polygon_template()\n    \n    group_mask = df[\"id\"].str.startswith(f\"{config_n:03d}_\")\n    group_data = df[group_mask].copy()\n    \n    xs = np.array([float(v[1:]) for v in group_data[\"x\"]])\n    ys = np.array([float(v[1:]) for v in group_data[\"y\"]])\n    degs = np.array([float(v[1:]) for v in group_data[\"deg\"]])\n    \n    n_trees = len(xs)\n    if n_trees <= 1:\n        return False, 0\n    \n    original_score = score_group_fast(xs, ys, degs, tx, ty)\n    best_score = original_score\n    best_xs, best_ys, best_degs = xs.copy(), ys.copy(), degs.copy()\n    \n    step = 0.0005\n    rot_step = 0.2\n    \n    for _ in range(iterations):\n        boundary_trees = set(find_boundary_trees(xs, ys, degs, tx, ty))\n        \n        for tree_idx in boundary_trees:\n            mnx, mny, mxx, mxy = get_bounding_box(xs, ys, degs, tx, ty)\n            cx = (mnx + mxx) / 2\n            cy = (mny + mxy) / 2\n            \n            dx = cx - xs[tree_idx]\n            dy = cy - ys[tree_idx]\n            norm = np.sqrt(dx*dx + dy*dy)\n            if norm > 1e-10:\n                dx, dy = dx/norm * step, dy/norm * step\n            \n            # Try translation\n            new_xs = xs.copy()\n            new_ys = ys.copy()\n            new_xs[tree_idx] += dx\n            new_ys[tree_idx] += dy\n            \n            new_score = score_group_fast(new_xs, new_ys, degs, tx, ty)\n            if new_score < best_score:\n                # CRITICAL: Check overlaps!\n                if not has_overlap_arrays(new_xs, new_ys, degs):\n                    best_score = new_score\n                    xs, ys = new_xs, new_ys\n                    best_xs, best_ys = xs.copy(), ys.copy()\n            \n            # Try rotation\n            for drot in [-rot_step, rot_step]:\n                new_degs = degs.copy()\n                new_degs[tree_idx] += drot\n                new_score = score_group_fast(xs, ys, new_degs, tx, ty)\n                if new_score < best_score:\n                    # CRITICAL: Check overlaps!\n                    if not has_overlap_arrays(xs, ys, new_degs):\n                        best_score = new_score\n                        degs = new_degs\n                        best_degs = degs.copy()\n    \n    improved = best_score < original_score - 1e-15\n    if improved:\n        if not has_overlap_arrays(best_xs, best_ys, best_degs):\n            indices = df[group_mask].index\n            for i, idx in enumerate(indices):\n                df.at[idx, 'x'] = f\"s{best_xs[i]}\"\n                df.at[idx, 'y'] = f\"s{best_ys[i]}\"\n                df.at[idx, 'deg'] = f\"s{best_degs[i]}\"\n        else:\n            improved = False\n    \n    return improved, original_score - best_score if improved else 0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPROVEMENT 4: Gradient descent (WITH OVERLAP CHECK)\n# ============================================================\n\ndef gradient_descent_config(df, config_n, steps=30, learning_rate=0.0001):\n    \"\"\"\n    Gradient descent with overlap validation.\n    \"\"\"\n    tx, ty = make_polygon_template()\n    \n    group_mask = df[\"id\"].str.startswith(f\"{config_n:03d}_\")\n    group_data = df[group_mask].copy()\n    \n    xs = np.array([float(v[1:]) for v in group_data[\"x\"]])\n    ys = np.array([float(v[1:]) for v in group_data[\"y\"]])\n    degs = np.array([float(v[1:]) for v in group_data[\"deg\"]])\n    \n    n_trees = len(xs)\n    if n_trees <= 1:\n        return False, 0\n    \n    original_score = score_group_fast(xs, ys, degs, tx, ty)\n    best_score = original_score\n    best_xs, best_ys, best_degs = xs.copy(), ys.copy(), degs.copy()\n    \n    eps = 1e-7\n    \n    for step in range(steps):\n        grad_x = np.zeros(n_trees)\n        grad_y = np.zeros(n_trees)\n        \n        for i in range(n_trees):\n            xs_plus = xs.copy(); xs_plus[i] += eps\n            xs_minus = xs.copy(); xs_minus[i] -= eps\n            grad_x[i] = (score_group_fast(xs_plus, ys, degs, tx, ty) - \n                        score_group_fast(xs_minus, ys, degs, tx, ty)) / (2 * eps)\n            \n            ys_plus = ys.copy(); ys_plus[i] += eps\n            ys_minus = ys.copy(); ys_minus[i] -= eps\n            grad_y[i] = (score_group_fast(xs, ys_plus, degs, tx, ty) - \n                        score_group_fast(xs, ys_minus, degs, tx, ty)) / (2 * eps)\n        \n        new_xs = xs - learning_rate * grad_x\n        new_ys = ys - learning_rate * grad_y\n        \n        new_score = score_group_fast(new_xs, new_ys, degs, tx, ty)\n        \n        # CRITICAL: Only accept if no overlaps\n        if new_score < best_score and not has_overlap_arrays(new_xs, new_ys, degs):\n            xs, ys = new_xs, new_ys\n            best_score = new_score\n            best_xs, best_ys, best_degs = xs.copy(), ys.copy(), degs.copy()\n    \n    improved = best_score < original_score - 1e-15\n    if improved:\n        if not has_overlap_arrays(best_xs, best_ys, best_degs):\n            indices = df[group_mask].index\n            for i, idx in enumerate(indices):\n                df.at[idx, 'x'] = f\"s{best_xs[i]}\"\n                df.at[idx, 'y'] = f\"s{best_ys[i]}\"\n                df.at[idx, 'deg'] = f\"s{best_degs[i]}\"\n        else:\n            improved = False\n    \n    return improved, original_score - best_score if improved else 0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPROVEMENT 5: Rotation grid search (WITH OVERLAP CHECK)\n# ============================================================\n\ndef rotation_grid_search(df, config_n, angle_step=15):\n    \"\"\"\n    Try discrete rotation angles with overlap validation.\n    \"\"\"\n    tx, ty = make_polygon_template()\n    \n    group_mask = df[\"id\"].str.startswith(f\"{config_n:03d}_\")\n    group_data = df[group_mask].copy()\n    \n    xs = np.array([float(v[1:]) for v in group_data[\"x\"]])\n    ys = np.array([float(v[1:]) for v in group_data[\"y\"]])\n    degs = np.array([float(v[1:]) for v in group_data[\"deg\"]])\n    \n    n_trees = len(xs)\n    if n_trees <= 1:\n        return False, 0\n    \n    original_score = score_group_fast(xs, ys, degs, tx, ty)\n    best_score = original_score\n    best_degs = degs.copy()\n    \n    boundary_trees = set(find_boundary_trees(xs, ys, degs, tx, ty))\n    angles_to_try = np.arange(-180, 180, angle_step)\n    \n    for tree_idx in boundary_trees:\n        current_best_angle = degs[tree_idx]\n        \n        for angle in angles_to_try:\n            test_degs = degs.copy()\n            test_degs[tree_idx] = angle\n            \n            score = score_group_fast(xs, ys, test_degs, tx, ty)\n            if score < best_score:\n                # CRITICAL: Check overlaps!\n                if not has_overlap_arrays(xs, ys, test_degs):\n                    best_score = score\n                    current_best_angle = angle\n        \n        degs[tree_idx] = current_best_angle\n        best_degs = degs.copy()\n    \n    improved = best_score < original_score - 1e-15\n    if improved:\n        if not has_overlap_arrays(xs, ys, best_degs):\n            indices = df[group_mask].index\n            for i, idx in enumerate(indices):\n                df.at[idx, 'deg'] = f\"s{best_degs[i]}\"\n        else:\n            improved = False\n    \n    return improved, original_score - best_score if improved else 0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPROVEMENT 6: Basin Hopping (WITH OVERLAP CHECK)\n# ============================================================\n\ndef basin_hopping_config(df, config_n, hops=10, local_steps=50):\n    \"\"\"\n    Basin hopping with overlap validation.\n    \"\"\"\n    tx, ty = make_polygon_template()\n    \n    group_mask = df[\"id\"].str.startswith(f\"{config_n:03d}_\")\n    group_data = df[group_mask].copy()\n    \n    xs = np.array([float(v[1:]) for v in group_data[\"x\"]])\n    ys = np.array([float(v[1:]) for v in group_data[\"y\"]])\n    degs = np.array([float(v[1:]) for v in group_data[\"deg\"]])\n    \n    n_trees = len(xs)\n    if n_trees <= 1:\n        return False, 0\n    \n    original_score = score_group_fast(xs, ys, degs, tx, ty)\n    best_score = original_score\n    best_xs, best_ys, best_degs = xs.copy(), ys.copy(), degs.copy()\n    \n    perturbation_size = BASIN_HOP_PERTURBATION / np.sqrt(n_trees)\n    \n    for hop in range(hops):\n        # Large perturbation\n        perturbed_xs = xs + np.random.uniform(-perturbation_size, perturbation_size, n_trees)\n        perturbed_ys = ys + np.random.uniform(-perturbation_size, perturbation_size, n_trees)\n        perturbed_degs = degs + np.random.uniform(-10, 10, n_trees)\n        \n        # Skip if perturbation causes overlap\n        if has_overlap_arrays(perturbed_xs, perturbed_ys, perturbed_degs):\n            continue\n        \n        local_xs, local_ys, local_degs = perturbed_xs.copy(), perturbed_ys.copy(), perturbed_degs.copy()\n        local_score = score_group_fast(local_xs, local_ys, local_degs, tx, ty)\n        \n        step = 0.001 / np.sqrt(n_trees)\n        \n        # Local optimization with overlap checking\n        for _ in range(local_steps):\n            tree_idx = random.randint(0, n_trees - 1)\n            \n            for dx, dy in [(step, 0), (-step, 0), (0, step), (0, -step)]:\n                test_xs = local_xs.copy()\n                test_ys = local_ys.copy()\n                test_xs[tree_idx] += dx\n                test_ys[tree_idx] += dy\n                \n                test_score = score_group_fast(test_xs, test_ys, local_degs, tx, ty)\n                if test_score < local_score:\n                    # Check overlaps only for improvements\n                    if not has_overlap_arrays(test_xs, test_ys, local_degs):\n                        local_xs, local_ys = test_xs, test_ys\n                        local_score = test_score\n        \n        if local_score < best_score:\n            # Final validation\n            if not has_overlap_arrays(local_xs, local_ys, local_degs):\n                best_score = local_score\n                best_xs, best_ys, best_degs = local_xs.copy(), local_ys.copy(), local_degs.copy()\n                xs, ys, degs = local_xs, local_ys, local_degs\n    \n    improved = best_score < original_score - 1e-15\n    if improved:\n        if not has_overlap_arrays(best_xs, best_ys, best_degs):\n            indices = df[group_mask].index\n            for i, idx in enumerate(indices):\n                df.at[idx, 'x'] = f\"s{best_xs[i]}\"\n                df.at[idx, 'y'] = f\"s{best_ys[i]}\"\n                df.at[idx, 'deg'] = f\"s{best_degs[i]}\"\n        else:\n            improved = False\n    \n    return improved, original_score - best_score if improved else 0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# Adaptive Parameter Selector\n# ============================================================\n\nclass AdaptiveParameterSelector:\n    def __init__(self):\n        self.successes = defaultdict(int)\n        self.attempts = defaultdict(int)\n        self.improvement_sum = defaultdict(float)\n        self.n_range = (30, 400)\n        self.r_range = (10, 50)\n        self.good_params = [\n            (72, 34), (100, 25), (50, 30), (150, 20), (80, 35),\n            (60, 40), (120, 28), (90, 32), (200, 22), (40, 38),\n            (180, 18), (75, 36), (110, 26), (65, 33), (140, 24),\n            (85, 30), (95, 28), (55, 35), (130, 22), (160, 20)\n        ]\n    \n    def get_params(self, exploration_rate=0.25):\n        if random.random() < exploration_rate or not self.successes:\n            if random.random() < 0.6 and self.good_params:\n                return random.choice(self.good_params)\n            return (random.randint(*self.n_range), random.randint(*self.r_range))\n        \n        weights, params = [], []\n        for (n, r), successes in self.successes.items():\n            attempts = self.attempts[(n, r)]\n            if attempts > 0:\n                rate = successes / attempts\n                improvement = self.improvement_sum[(n, r)] / max(attempts, 1)\n                weight = (rate + 0.1) * (1 + improvement * 1e8)\n                weights.append(weight)\n                params.append((n, r))\n        \n        if weights:\n            total = sum(weights)\n            idx = random.choices(range(len(params)), [w/total for w in weights])[0]\n            return params[idx]\n        return self.get_params(exploration_rate=1.0)\n    \n    def record_result(self, n, r, improved, improvement=0):\n        self.attempts[(n, r)] += 1\n        if improved:\n            self.successes[(n, r)] += 1\n            self.improvement_sum[(n, r)] += improvement\n            if (n, r) not in self.good_params:\n                self.good_params.append((n, r))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MAIN OPTIMIZATION LOOP - V2 FIXED\n# ============================================================\n\ndef main():\n    start_time = time.time()\n    \n    df = pd.read_csv(\"submission.csv\")\n    initial_score, initial_scores = eval_df_sub(df, False)\n    best_score = initial_score\n    best_df = df.copy()\n    \n    param_selector = AdaptiveParameterSelector()\n    \n    sorted_configs = sorted(initial_scores.items(), key=lambda x: x[1], reverse=True)\n    worst_configs = [c[0] for c in sorted_configs[:60]]\n    \n    print(f\"\\nüéØ Top 5 worst configs: {worst_configs[:5]}\")\n    print(f\"üöÄ Starting V2 optimization (time: {MAX_TIME_SECONDS/3600:.1f}h)\")\n    print(\"=\"*70)\n    \n    cycle = 0\n    total_bbox3_improvements = 0\n    total_local_improvements = 0\n    \n    while time.time() - start_time < MAX_TIME_SECONDS:\n        cycle += 1\n        elapsed = time.time() - start_time\n        \n        print(f\"\\n--- Cycle {cycle} ({elapsed/60:.1f}m elapsed) ---\")\n        \n        # Phase 1: bbox3 runs (these handle overlaps internally)\n        print(\"  [Phase 1] bbox3 optimization\")\n        for _ in range(3):\n            if time.time() - start_time >= MAX_TIME_SECONDS:\n                break\n            \n            n, r = param_selector.get_params()\n            prev_score = best_score\n            \n            try:\n                subprocess.run([\"./bbox3\", \"-n\", str(n), \"-r\", str(r)],\n                             capture_output=True, timeout=BBOX3_TIMEOUT)\n            except subprocess.TimeoutExpired:\n                print(f\"    ‚è±Ô∏è bbox3 timeout\")\n                continue\n            \n            df = pd.read_csv(\"submission.csv\")\n            new_score, _ = eval_df_sub(df, False)\n            \n            improvement = prev_score - new_score\n            improved = improvement > 1e-15\n            param_selector.record_result(n, r, improved, improvement)\n            \n            if new_score < best_score:\n                best_score = new_score\n                best_df = df.copy()\n                total_bbox3_improvements += 1\n                print(f\"    ‚úÖ bbox3 n={n} r={r}: {improvement:.12f}\")\n        \n        # Phase 2: Local optimization (now with overlap checks!)\n        if time.time() - start_time < MAX_TIME_SECONDS:\n            print(\"  [Phase 2] Local optimization\")\n            \n            _, current_scores = eval_df_sub(df, False)\n            sorted_configs = sorted(current_scores.items(), key=lambda x: x[1], reverse=True)\n            worst_configs = [c[0] for c in sorted_configs[:40]]\n            \n            configs_to_optimize = random.sample(worst_configs, min(10, len(worst_configs)))\n            \n            for config_n in configs_to_optimize:\n                if time.time() - start_time >= MAX_TIME_SECONDS:\n                    break\n                \n                strategies = [\n                    ('SA', lambda: simulated_annealing_config(df, config_n, SA_ITERATIONS)),\n                    ('Boundary', lambda: optimize_boundary_trees(df, config_n, 80)),\n                    ('Gradient', lambda: gradient_descent_config(df, config_n, GRADIENT_STEPS)),\n                    ('Swap', lambda: try_swap_trees(df, config_n, 30)),\n                ]\n                \n                strategy_name, strategy_fn = random.choice(strategies)\n                try:\n                    improved, gain = strategy_fn()\n                    if improved:\n                        total_local_improvements += 1\n                        print(f\"    ‚úÖ {strategy_name} on config {config_n}: {gain:.12f}\")\n                except Exception as e:\n                    print(f\"    ‚ö†Ô∏è {strategy_name} error on config {config_n}: {e}\")\n        \n        # Phase 3: Rotation (every 3 cycles)\n        if cycle % 3 == 0 and time.time() - start_time < MAX_TIME_SECONDS:\n            print(\"  [Phase 3] Rotation grid search\")\n            for config_n in random.sample(worst_configs, min(5, len(worst_configs))):\n                try:\n                    improved, gain = rotation_grid_search(df, config_n, angle_step=10)\n                    if improved:\n                        print(f\"    ‚úÖ Rotation on config {config_n}: {gain:.12f}\")\n                except Exception as e:\n                    pass\n        \n        # Phase 4: Basin hopping (every 5 cycles)\n        if cycle % 5 == 0 and time.time() - start_time < MAX_TIME_SECONDS:\n            print(\"  [Phase 4] Basin hopping\")\n            for config_n in random.sample(worst_configs, min(3, len(worst_configs))):\n                try:\n                    improved, gain = basin_hopping_config(df, config_n, hops=5, local_steps=40)\n                    if improved:\n                        print(f\"    ‚úÖ Basin hop on config {config_n}: {gain:.12f}\")\n                except Exception as e:\n                    pass\n        \n        # Save and validate\n        df.to_csv(\"submission.csv\", index=False)\n        new_score, _ = eval_df_sub(df, False)\n        \n        if new_score < best_score:\n            best_score = new_score\n            best_df = df.copy()\n            print(f\"  üìà New best: {best_score:.12f}\")\n        \n        if cycle % 10 == 0:\n            print(f\"\\n  === Status: Score={best_score:.12f}, \"\n                  f\"bbox3={total_bbox3_improvements}, local={total_local_improvements} ===\")\n    \n    # Final save with best found\n    best_df.to_csv(\"submission.csv\", index=False)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"OPTIMIZATION COMPLETE\")\n    print(\"=\"*70)\n    final_score, _ = eval_df_sub(best_df, False)\n    \n    print(f\"\\nüìà Results:\")\n    print(f\"   Initial:  {initial_score:.12f}\")\n    print(f\"   Final:    {final_score:.12f}\")\n    print(f\"   Improved: {initial_score - final_score:.12f}\")\n    print(f\"   Cycles:   {cycle}\")\n    print(f\"   bbox3 improvements: {total_bbox3_improvements}\")\n    print(f\"   Local improvements: {total_local_improvements}\")\n    print(f\"   Total time: {(time.time()-start_time)/3600:.2f}h\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Last ensemble","metadata":{}},{"cell_type":"code","source":"!python3 ./ensemble_submissions.py -d /kaggle/working -o /kaggle/working/submission_final.csv\n!mv /kaggle/working/submission_final.csv /kaggle/working/submission.csv","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}