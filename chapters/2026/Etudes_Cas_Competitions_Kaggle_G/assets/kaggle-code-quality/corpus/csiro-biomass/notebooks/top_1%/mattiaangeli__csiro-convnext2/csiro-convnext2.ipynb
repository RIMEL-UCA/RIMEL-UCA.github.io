{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":724135,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":551055,"modelId":563667}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ========= ConvNeXt/ConvNeXtV2 (only) â€” load folds + infer + make submission =========\nimport os, glob, math, cv2\nimport numpy as np\nimport pandas as pd\nimport torch, torch.nn as nn\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\n\n# ----------------- CONFIG -----------------\nMODEL_NAME  = \"convnextv2_huge.fcmae_ft_in22k_in1k_512\"   # change if you trained a different one\nIMG_SIZE    = 512\nBATCH_SIZE  = 8\nNUM_WORKERS = 2\n\nTEST_CSV    = \"/kaggle/input/csiro-biomass/test.csv\"\nWEIGHTS_DIR = \"/kaggle/input/convnext2/pytorch/default/1/convnextv2\"  # contains best_model_fold0.pth ...\nOUT_CSV     = \"submission.csv\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.backends.cudnn.benchmark = True\ntorch.set_float32_matmul_precision(\"high\")\n\nTARGET_COLS = [\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\",\"GDM_g\",\"Dry_Total_g\"]\nMEAN = np.array([0.485, 0.456, 0.406], np.float32)\nSTD  = np.array([0.229, 0.224, 0.225], np.float32)\n\n# ----------------- utils -----------------\ndef clean_image(img_rgb):\n    h, w = img_rgb.shape[:2]\n    img = img_rgb[: int(h * 0.90), :]\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    mask = cv2.inRange(hsv, np.array([5,150,150]), np.array([25,255,255]))\n    mask = cv2.dilate(mask, np.ones((3,3), np.uint8), iterations=2)\n    if mask.sum() > 0:\n        img = cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n    return img\n\ndef preprocess_half(img_rgb, size):\n    im = cv2.resize(img_rgb, (size, size), interpolation=cv2.INTER_LINEAR).astype(np.float32) / 255.0\n    im = (im - MEAN) / STD\n    return torch.from_numpy(im).permute(2, 0, 1)  # CHW\n\ndef resolve_path(rel_path, base_dirs):\n    for bd in base_dirs:\n        p = os.path.join(bd, rel_path)\n        if os.path.exists(p): return p\n    bn = os.path.basename(rel_path)\n    for bd in base_dirs:\n        p = os.path.join(bd, bn)\n        if os.path.exists(p): return p\n    return None\n\nclass TestDS(Dataset):\n    def __init__(self, image_paths, base_dirs):\n        self.image_paths = list(image_paths)\n        self.base_dirs = list(base_dirs)\n\n    def __len__(self): return len(self.image_paths)\n\n    def __getitem__(self, i):\n        rel = self.image_paths[i]\n        fp = resolve_path(rel, self.base_dirs)\n        img = cv2.imread(fp) if fp else None\n        if img is None:\n            img = np.zeros((1000, 2000, 3), np.uint8)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = clean_image(img)\n        mid = img.shape[1] // 2\n        left  = preprocess_half(img[:, :mid], IMG_SIZE)\n        right = preprocess_half(img[:, mid:], IMG_SIZE)\n        return left, right, rel\n\n# ----------------- model -----------------\nclass Local2DTokenMixerBlock(nn.Module):\n    def __init__(self, dim, k=5, drop=0.1):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.gate = nn.Linear(dim, dim)\n        self.dw   = nn.Conv2d(dim, dim, k, padding=k//2, groups=dim, bias=True)\n        self.proj = nn.Linear(dim, dim)\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x):  # (B,H,W,C)\n        s = x\n        x = self.norm(x)\n        x = x * torch.sigmoid(self.gate(x))\n        x = x.permute(0,3,1,2)\n        x = self.dw(x)\n        x = x.permute(0,2,3,1)\n        x = self.proj(x)\n        x = self.drop(x)\n        return s + x\n\nclass BiomassConvNeXt(nn.Module):\n    def __init__(self, name):\n        super().__init__()\n        self.backbone = timm.create_model(name, pretrained=False, features_only=True)\n        in_ch = int(self.backbone.feature_info.channels()[-1])\n        self.nf = in_ch\n\n        self.fuse = nn.Sequential(\n            Local2DTokenMixerBlock(self.nf, k=5, drop=0.1),\n            Local2DTokenMixerBlock(self.nf, k=5, drop=0.1),\n        )\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.ln   = nn.LayerNorm(self.nf)\n\n        def head():\n            return nn.Sequential(\n                nn.Linear(self.nf, self.nf//2),\n                nn.GELU(),\n                nn.Dropout(0.2),\n                nn.Linear(self.nf//2, 1),\n                nn.Softplus(),\n            )\n        self.h_green  = head()\n        self.h_clover = head()\n        self.h_dead   = head()\n\n    def _featmap(self, x):\n        feats = self.backbone(x)\n        return feats[-1] if isinstance(feats, (list, tuple)) else feats  # (B,C,H,W)\n\n    def forward(self, left, right):\n        fl = self._featmap(left)\n        fr = self._featmap(right)\n        f  = torch.cat([fl, fr], dim=3)          # (B,C,H,2W)\n        f  = f.permute(0,2,3,1).contiguous()     # (B,H,2W,C)\n        with torch.amp.autocast(\"cuda\", enabled=False):\n            f  = self.fuse(f.float())\n            B,H,W,C = f.shape\n            seq = f.view(B, H*W, C)\n            feat = self.pool(seq.transpose(1,2)).squeeze(-1)\n            feat = self.ln(feat)\n\n        green  = self.h_green(feat)\n        clover = self.h_clover(feat)\n        dead   = self.h_dead(feat)\n        gdm    = green + clover\n        total  = gdm + dead\n        return green, dead, clover, gdm, total  # match TARGET_COLS order (except names)\n\n# ----------------- load + infer -----------------\ndef load_sd(path):\n    s = torch.load(path, map_location=\"cpu\")\n    if isinstance(s, dict) and (\"model_state_dict\" in s or \"state_dict\" in s):\n        s = s.get(\"model_state_dict\", s.get(\"state_dict\"))\n    return s\n\n@torch.inference_mode()\ndef predict_ckpt(model, loader, ckpt):\n    model.load_state_dict(load_sd(ckpt), strict=False)\n    model.to(DEVICE).eval()\n\n    out = np.zeros((len(loader.dataset), 5), np.float32)\n    off = 0\n    for l, r, _ in loader:\n        l = l.to(DEVICE, non_blocking=True)\n        r = r.to(DEVICE, non_blocking=True)\n        if DEVICE.type == \"cuda\":\n            with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n                y = model(l, r)\n        else:\n            y = model(l, r)\n        y = torch.stack([t.view(-1) for t in y], dim=1).float().cpu().numpy()\n        b = l.size(0)\n        out[off:off+b] = y\n        off += b\n    return out\n\n# ----------------- run -----------------\ntest_df = pd.read_csv(TEST_CSV)\nuniq_imgs = test_df[\"image_path\"].drop_duplicates().values\n\nbase_dirs = [\n    \"/kaggle/input/csiro-biomass\",\n    \"/kaggle/input/csiro-biomass/test_images\",\n    \"/kaggle/input/csiro-biomass/test\",\n]\n\nds = TestDS(uniq_imgs, base_dirs)\ndl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\nckpts = sorted(glob.glob(os.path.join(WEIGHTS_DIR, \"best_model_fold*.pth\")))\nif not ckpts:\n    raise FileNotFoundError(f\"No checkpoints like best_model_fold*.pth in: {WEIGHTS_DIR}\")\n\nmodel = BiomassConvNeXt(MODEL_NAME)\npred = np.zeros((len(ds), 5), np.float32)\nfor p in ckpts:\n    pred += predict_ckpt(model, dl, p)\npred /= float(len(ckpts))\n\npreds_wide = pd.DataFrame(pred, columns=TARGET_COLS)\npreds_wide.insert(0, \"image_path\", uniq_imgs)\n\npreds_long = preds_wide.melt(\n    id_vars=[\"image_path\"],\n    value_vars=TARGET_COLS,\n    var_name=\"target_name\",\n    value_name=\"target\",\n)\n\nsub = (\n    test_df[[\"sample_id\", \"image_path\", \"target_name\"]]\n    .merge(preds_long, on=[\"image_path\", \"target_name\"], how=\"left\")[[\"sample_id\", \"target\"]]\n    .fillna(0.0)\n    .sort_values(\"sample_id\")\n    .reset_index(drop=True)\n)\n\nsub.to_csv(OUT_CSV, index=False)\nprint(\"saved:\", OUT_CSV)\nsub.head()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}