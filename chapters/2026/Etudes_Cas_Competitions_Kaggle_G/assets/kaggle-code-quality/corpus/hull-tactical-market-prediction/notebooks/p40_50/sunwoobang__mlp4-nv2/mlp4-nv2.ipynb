{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":111543,"databundleVersionId":14348714,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# =========================================================================================\n### TITLE: Hull Tactical - Advanced Online Ensemble (XGB+LGBM+CAT)\n### AUTHOR: AI Machine Learning Engineer\n### DESCRIPTION: \n### This notebook implements a State-of-the-Art (SOTA) approach for financial time-series \n### forecasting. It utilizes an Online Learning strategy where the model retrains/updates \n### incrementally as new market data arrives via the API. This adapts to 'Concept Drift' \n### in financial markets.\n###\n### STRATEGY:\n### 1. Data Processing: Polars for high-speed I/O, Pandas for model compatibility.\n### 2. Feature Engineering: Lag features and rolling window statistics.\n### 3. Model Architecture: Weighted Ensemble of XGBoost, LightGBM, and CatBoost.\n### 4. Inference Strategy: \"Walk-Forward\" validation and retraining loop via Kaggle API.\n### 5. Edit) add Catboost\n### =========================================================================================","metadata":{}},{"cell_type":"code","source":"# =========================================================================================\n# TITLE: Hull Tactical - Gen3 Hybrid SOTA (Linear + Boost + Volatility Scaling)\n# AUTHOR: AI Machine Learning Engineer\n# STRATEGY:\n# 1. Hybrid Model: ElasticNet (Online Learning) + LightGBM (Non-Linear patterns).\n# 2. Advanced Features: Rolling Volatility & Momentum (RSI-like).\n# 3. Volatility Targeting: Reduces bet size when market risk is high (The Gold Medal Key).\n# =========================================================================================\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nimport kaggle_evaluation.default_inference_server\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:50:33.966266Z","iopub.execute_input":"2025-11-24T13:50:33.966507Z","iopub.status.idle":"2025-11-24T13:50:41.613117Z","shell.execute_reply.started":"2025-11-24T13:50:33.966484Z","shell.execute_reply":"2025-11-24T13:50:41.612447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------------------------------------------------------------------\n# 1. CONFIGURATION\n# -----------------------------------------------------------------------------------------\nclass Config:\n    SEED = 42\n\n    # Ensemble weights for 3 models\n    W_LINEAR = 0.3   # SGDRegressor\n    W_LGBM   = 0.4   # LightGBM\n    W_CAT    = 0.3   # CatBoost\n\n    # Volatility Targeting\n    TARGET_VOL = 0.005          # 목표 일일 변동성 (0.5%)\n    MAX_LEVERAGE = 1.2          # ★ 전략 포지션 상한을 1.2로 줄여서 sigma_strat <= 1.2 * sigma_mkt 근사 보장\n\n    # Online Learning rate for SGDRegressor\n    SGD_LR = 0.001\n\n    # 포지션 민감도 (예측/변동성 → 포지션으로 바꾸는 스케일)\n    SIGNAL_SCALE = 5.0          # 너무 크면 변동성 폭발, 너무 작으면 거의 1 근처. 필요하면 튜닝.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:50:41.614652Z","iopub.execute_input":"2025-11-24T13:50:41.615126Z","iopub.status.idle":"2025-11-24T13:50:41.61924Z","shell.execute_reply.started":"2025-11-24T13:50:41.615107Z","shell.execute_reply":"2025-11-24T13:50:41.61846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------------------------------------------------------------------\n# 2. FEATURE ENGINEERING\n# -----------------------------------------------------------------------------------------\ndef feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n\n    # lag를 만들 기준 컬럼들 (train에는 존재 / test에는 forward_returns가 없음)\n    targets = ['forward_returns', 'risk_free_rate']\n\n    # 1. Lag Features\n    for col in targets:\n        if col in df.columns:\n            for lag in [1, 2, 3, 5, 10]:\n                df[f'lag_{col}_{lag}'] = df[col].shift(lag)\n\n    # 2. Volatility Features (최근 risk)\n    base_col = 'lag_forward_returns_1'\n    if base_col not in df.columns and 'forward_returns' in df.columns:\n        # forward_returns 기준으로 1일 lag 직접 생성\n        df[base_col] = df['forward_returns'].shift(1)\n\n    # 안전장치: 컬럼이 없다면 0으로 생성\n    if base_col not in df.columns:\n        df[base_col] = 0.0\n\n    df['vol_5d']  = df[base_col].rolling(5).std()\n    df['vol_22d'] = df[base_col].rolling(22).std()  # 약 한달\n\n    # 3. Momentum Features\n    df['mom_5d']  = df[base_col].rolling(5).mean()\n    df['mom_22d'] = df[base_col].rolling(22).mean()\n\n    # 4. Z-score (비정상적인 구간인지)\n    df['zscore_22'] = (df[base_col] - df['mom_22d']) / (df['vol_22d'] + 1e-8)\n\n    # 5. 결측값 처리\n    df = df.fillna(0.0)\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:50:41.620104Z","iopub.execute_input":"2025-11-24T13:50:41.620437Z","iopub.status.idle":"2025-11-24T13:50:41.637463Z","shell.execute_reply.started":"2025-11-24T13:50:41.620413Z","shell.execute_reply":"2025-11-24T13:50:41.636858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------------------------------------------------------------------\n# 3. DATA LOADING\n# -----------------------------------------------------------------------------------------\ndef load_data(path: str) -> pd.DataFrame:\n    print(f\"Loading {path}...\")\n    df_pl = pl.read_csv(path)\n    cols = [c for c in df_pl.columns if c != 'date_id']\n    # 숫자형으로 캐스팅 + null -> 0\n    df_pl = df_pl.with_columns(\n        [pl.col(c).cast(pl.Float64, strict=False).fill_null(0.0) for c in cols]\n    )\n    return df_pl.to_pandas()\n\n\nTRAIN_PATH = \"/kaggle/input/hull-tactical-market-prediction/train.csv\"\ntrain_df = load_data(TRAIN_PATH)\ntrain_df = train_df[:-180]\n\n# Feature Engineering\ntrain_df = feature_engineering(train_df)\n\n# 앞쪽 lag 계산이 충분히 안 된 구간 잘라냄\ntrain_df = train_df.iloc[25:].reset_index(drop=True)\n\nTARGET = \"forward_returns\"\nDROP_COLS = [\n    'date_id', 'is_scored',\n    'forward_returns', 'risk_free_rate',\n    'market_forward_excess_returns'\n]\n\nFEATURES = [c for c in train_df.columns if c not in DROP_COLS]\nprint(f\"Features Created: {len(FEATURES)}\")\n\nX = train_df[FEATURES]\ny = train_df[TARGET]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:50:41.638302Z","iopub.execute_input":"2025-11-24T13:50:41.638573Z","iopub.status.idle":"2025-11-24T13:50:41.988561Z","shell.execute_reply.started":"2025-11-24T13:50:41.638522Z","shell.execute_reply":"2025-11-24T13:50:41.987726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------------------------------------------------------------------\n# 4. HYBRID MODEL TRAINING\n# -----------------------------------------------------------------------------------------\n\nprint(\"Training 3 base models (SGD, LGBM, CatBoost)...\")\n\n# 4-1. Linear Model (SGDRegressor, online 가능)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nlinear_model = SGDRegressor(\n    loss='squared_error',\n    penalty='l2',\n    alpha=0.01,\n    learning_rate='constant',\n    eta0=Config.SGD_LR,\n    random_state=Config.SEED\n)\nlinear_model.fit(X_scaled, y)\n\n# 4-2. LightGBM\nlgbm_model = LGBMRegressor(\n    n_estimators=600,\n    learning_rate=0.02,\n    max_depth=5,\n    num_leaves=31,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=Config.SEED,\n    n_jobs=-1,\n    verbose=-1\n)\nlgbm_model.fit(X, y)\n\n# 4-3. CatBoost\ncat_model = CatBoostRegressor(\n    depth=6,\n    learning_rate=0.03,\n    iterations=800,\n    loss_function='RMSE',\n    random_seed=Config.SEED,\n    verbose=False\n)\ncat_model.fit(X, y)\n\nprint(\"All base models trained.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:50:41.989406Z","iopub.execute_input":"2025-11-24T13:50:41.989698Z","iopub.status.idle":"2025-11-24T13:50:44.569865Z","shell.execute_reply.started":"2025-11-24T13:50:41.989673Z","shell.execute_reply":"2025-11-24T13:50:44.56871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------------------------------------------------------------------\n# 5. INFERENCE LOOP WITH VOLATILITY-AWARE SCALING\n# -----------------------------------------------------------------------------------------\nGLOBAL_HISTORY = train_df.iloc[-50:].copy()\nSTEP = 0\n\n\ndef predict(test_pl: pl.DataFrame) -> float:\n    global GLOBAL_HISTORY, STEP, linear_model, scaler\n\n    # 1. 입력 처리\n    cols = [c for c in test_pl.columns if c != 'date_id']\n    test_pl = test_pl.with_columns(\n        [pl.col(c).cast(pl.Float64, strict=False).fill_null(0.0) for c in cols]\n    )\n    test_df_raw = test_pl.to_pandas()\n\n    # 2. 히스토리 업데이트 & 피처 생성\n    GLOBAL_HISTORY = pd.concat([GLOBAL_HISTORY, test_df_raw], axis=0, ignore_index=True)\n    full_features = feature_engineering(GLOBAL_HISTORY)\n    current_features = full_features.iloc[[-1]][FEATURES]\n\n    # 3. 세 모델 예측\n    curr_X_scaled = scaler.transform(current_features)\n    pred_linear = linear_model.predict(curr_X_scaled)[0]\n    pred_lgbm  = lgbm_model.predict(current_features)[0]\n    pred_cat   = cat_model.predict(current_features)[0]\n\n    raw_return_pred = (\n        Config.W_LINEAR * pred_linear +\n        Config.W_LGBM   * pred_lgbm   +\n        Config.W_CAT    * pred_cat\n    )\n\n    # ---------------------------------------------------------------------\n    # 4. 변동성 기반 포지션 결정 (더 보수적인 버전)\n    # ---------------------------------------------------------------------\n    # 현재 시장 변동성 (22일 rolling)\n    current_vol = current_features['vol_22d'].values[0] if 'vol_22d' in current_features.columns else 0.005\n    if current_vol < 1e-6:\n        current_vol = 0.005\n\n    # signal: 예측 수익률을 변동성으로 나눈 값 (Sharpe 비슷한 개념)\n    signal = raw_return_pred / (current_vol + 1e-8)\n\n    # 너무 큰 signal이 들어오면 과도한 레버리지 방지\n    signal = np.clip(signal, -3.0, 3.0)\n\n    # 기본 포지션: 1.0(중립)에서 signal에 비례해 움직임\n    allocation = 1.0 + Config.SIGNAL_SCALE * signal\n\n    # Crash 보호: 장기 모멘텀이 크게 음수이면 롱 포지션 제한\n    mom_22 = current_features['mom_22d'].values[0] if 'mom_22d' in current_features.columns else 0.0\n    if mom_22 < -0.01 and allocation > 1.0:\n        allocation = 1.0\n\n    # [0, MAX_LEVERAGE]로 클리핑 (MAX_LEVERAGE=1.2 → 전략 변동성 ≤ 1.2 * 시장 변동성 근사 보장)\n    allocation = float(np.clip(allocation, 0.0, Config.MAX_LEVERAGE))\n\n    # ---------------------------------------------------------------------\n    # 5. Online Learning (SGD만 partial_fit)\n    # ---------------------------------------------------------------------\n    try:\n        prev_target = test_df_raw['lagged_forward_returns'].values[0]\n        linear_model.partial_fit(curr_X_scaled, [prev_target])\n    except Exception:\n        pass\n\n    # 히스토리 관리\n    if len(GLOBAL_HISTORY) > 200:\n        GLOBAL_HISTORY = GLOBAL_HISTORY.iloc[-100:]\n\n    STEP += 1\n    return allocation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:50:44.570505Z","iopub.execute_input":"2025-11-24T13:50:44.57072Z","iopub.status.idle":"2025-11-24T13:50:44.583382Z","shell.execute_reply.started":"2025-11-24T13:50:44.570703Z","shell.execute_reply":"2025-11-24T13:50:44.582605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------------------------------------------------------------------\n# 6. SERVER START\n# -----------------------------------------------------------------------------------------\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:50:44.585067Z","iopub.execute_input":"2025-11-24T13:50:44.585846Z","iopub.status.idle":"2025-11-24T13:50:44.920887Z","shell.execute_reply.started":"2025-11-24T13:50:44.585822Z","shell.execute_reply":"2025-11-24T13:50:44.920242Z"}},"outputs":[],"execution_count":null}]}