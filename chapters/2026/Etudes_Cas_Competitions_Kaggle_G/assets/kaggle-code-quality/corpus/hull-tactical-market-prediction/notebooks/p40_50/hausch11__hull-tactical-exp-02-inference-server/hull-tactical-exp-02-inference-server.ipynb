{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":14348714,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hull Tactical Market Prediction - EXP-02 Inference Server\n\n**Model:** LightGBM + Enhanced Tier 1 Features  \n**Local CV Performance:** Adjusted Sharpe 1.7461 (+273% vs baseline)  \n**IC:** 0.1067 Â± 0.1315  \n\n**CRITICAL:** This is an INFERENCE SERVER, not a static file submission!  \nThe predict() function is called once per timestep and must return a single float.","metadata":{}},{"cell_type":"markdown","source":"## Setup and Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport lightgbm as lgb\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport kaggle_evaluation.default_inference_server\n\nprint(\"=\" * 80)\nprint(\"HULL TACTICAL - EXP-02 INFERENCE SERVER\")\nprint(\"=\" * 80)\nprint(\"Model: LightGBM + Enhanced Tier 1 Features\")\nprint(\"Local CV Performance: Adjusted Sharpe 1.7461 (+273% vs baseline)\")\nprint(\"=\" * 80)\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:56:49.488836Z","iopub.execute_input":"2025-11-30T18:56:49.489828Z","iopub.status.idle":"2025-11-30T18:56:49.496264Z","shell.execute_reply.started":"2025-11-30T18:56:49.489798Z","shell.execute_reply":"2025-11-30T18:56:49.495205Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"# Hyperparameters (from winning model EXP-02)\nLGBM_PARAMS = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'n_estimators': 500,\n    'min_child_samples': 20,\n    'verbose': -1,\n    'random_state': 42\n}\n\n# Feature engineering parameters\nLAG_PERIODS = [1, 5, 10, 21]\nROLLING_WINDOWS = [5, 10, 21, 63]\nDOWNSIDE_WINDOWS = [21, 63]\n\n# Position mapping configuration\nSIGNAL_MULTIPLIER = 2.0  # Maps predictions to [0, 2] range\nMIN_POSITION = 0.0\nMAX_POSITION = 2.0\n\n# Target column\nTARGET_COL = 'market_forward_excess_returns'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:56:49.49774Z","iopub.execute_input":"2025-11-30T18:56:49.497973Z","iopub.status.idle":"2025-11-30T18:56:49.515597Z","shell.execute_reply.started":"2025-11-30T18:56:49.497954Z","shell.execute_reply":"2025-11-30T18:56:49.514725Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Model (runs once at startup)","metadata":{}},{"cell_type":"code","source":"print(\"=\" * 80)\nprint(\"TRAINING MODEL (runs once at startup)\")\nprint(\"=\" * 80)\nprint()\n\n# Load training data\ntrain_file = '/kaggle/input/hull-tactical-market-prediction/train.csv'\ntrain_df = pd.read_csv(train_file)\n\nprint(f\"âœ… Loaded {len(train_df):,} training rows\")\n\n# Feature Engineering on Training Data\nreturns = train_df[TARGET_COL]\n\n# Lag features\nfor lag in LAG_PERIODS:\n    train_df[f'return_lag_{lag}'] = returns.shift(lag)\n\n# Rolling statistics\nfor window in ROLLING_WINDOWS:\n    train_df[f'volatility_{window}d'] = returns.shift(1).rolling(window).std()\n    train_df[f'mean_return_{window}d'] = returns.shift(1).rolling(window).mean()\n\n# Downside deviation features\nfor window in DOWNSIDE_WINDOWS:\n    negative_returns = returns.shift(1).clip(upper=0)\n    train_df[f'downside_dev_{window}d'] = negative_returns.rolling(window).std()\n\n# Define feature columns\nFEATURE_COLS = []\nFEATURE_COLS.extend([f'return_lag_{lag}' for lag in LAG_PERIODS])\nfor window in ROLLING_WINDOWS:\n    FEATURE_COLS.extend([f'volatility_{window}d', f'mean_return_{window}d'])\nFEATURE_COLS.extend([f'downside_dev_{window}d' for window in DOWNSIDE_WINDOWS])\n\nprint(f\"Features: {len(FEATURE_COLS)} total\")\n\n# Prepare training data\nX_train = train_df[FEATURE_COLS].copy()\ny_train = train_df[TARGET_COL].copy()\n\n# Drop NaN rows\nvalid_mask = X_train.notna().all(axis=1) & y_train.notna()\nX_train = X_train[valid_mask]\ny_train = y_train[valid_mask]\n\n# Clean infinities\nX_train = X_train.replace([np.inf, -np.inf], np.nan)\nX_train = X_train.fillna(X_train.median())\n\nprint(f\"âœ… Training matrix: {len(X_train):,} samples Ã— {len(FEATURE_COLS)} features\")\n\n# Calculate feature medians for inference\nfeature_medians = {col: X_train[col].median() for col in FEATURE_COLS}\n\n# Train LightGBM model\nmodel = lgb.LGBMRegressor(**LGBM_PARAMS)\nmodel.fit(X_train, y_train)\n\nprint(f\"âœ… Model trained (LightGBM with {LGBM_PARAMS['n_estimators']} trees)\")\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:56:49.516646Z","iopub.execute_input":"2025-11-30T18:56:49.517019Z","iopub.status.idle":"2025-11-30T18:56:50.397725Z","shell.execute_reply.started":"2025-11-30T18:56:49.516989Z","shell.execute_reply":"2025-11-30T18:56:50.396747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Predict Function (returns position allocation [0, 2])","metadata":{}},{"cell_type":"code","source":"# Global state for maintaining rolling windows during inference\ninference_state = {\n    'returns_history': [],\n    'timestep': 0\n}\n\ndef predict(test: pl.DataFrame) -> float:\n    \"\"\"\n    Predict position allocation for inference server.\n    Called once per timestep by Kaggle's evaluation system.\n    \n    Args:\n        test: Polars DataFrame with test features (one row = one timestep)\n    \n    Returns:\n        float: Position allocation [0.0, 2.0]\n    \"\"\"\n    global model, feature_medians, FEATURE_COLS, inference_state\n    \n    # Convert Polars to Pandas\n    test_pd = test.to_pandas()\n    \n    # Extract current return (for updating state)\n    if 'lagged_market_forward_excess_returns' in test_pd.columns:\n        current_return = test_pd['lagged_market_forward_excess_returns'].iloc[0]\n    elif 'market_forward_excess_returns' in test_pd.columns:\n        current_return = test_pd['market_forward_excess_returns'].iloc[0]\n    else:\n        current_return = 0.0\n    \n    # Update returns history\n    inference_state['returns_history'].append(current_return)\n    \n    # Keep only last 300 timesteps\n    if len(inference_state['returns_history']) > 300:\n        inference_state['returns_history'] = inference_state['returns_history'][-300:]\n    \n    returns_arr = np.array(inference_state['returns_history'])\n    \n    # --- Feature Engineering for Current Timestep ---\n    \n    features_dict = {}\n    \n    # Lag features\n    for lag in LAG_PERIODS:\n        idx = -(lag + 1)\n        if len(returns_arr) >= (lag + 1):\n            features_dict[f'return_lag_{lag}'] = returns_arr[idx]\n        else:\n            features_dict[f'return_lag_{lag}'] = 0.0\n    \n    # Rolling statistics\n    for window in ROLLING_WINDOWS:\n        if len(returns_arr) >= window + 1:\n            window_data = returns_arr[-(window+1):-1]\n            features_dict[f'volatility_{window}d'] = np.std(window_data)\n            features_dict[f'mean_return_{window}d'] = np.mean(window_data)\n        else:\n            if len(returns_arr) > 1:\n                features_dict[f'volatility_{window}d'] = np.std(returns_arr[:-1])\n                features_dict[f'mean_return_{window}d'] = np.mean(returns_arr[:-1])\n            else:\n                features_dict[f'volatility_{window}d'] = 0.01\n                features_dict[f'mean_return_{window}d'] = 0.0\n    \n    # Downside deviation features\n    for window in DOWNSIDE_WINDOWS:\n        if len(returns_arr) >= window + 1:\n            window_data = returns_arr[-(window+1):-1]\n            negative_returns = np.clip(window_data, None, 0)\n            features_dict[f'downside_dev_{window}d'] = np.std(negative_returns)\n        else:\n            if len(returns_arr) > 1:\n                negative_returns = np.clip(returns_arr[:-1], None, 0)\n                features_dict[f'downside_dev_{window}d'] = np.std(negative_returns)\n            else:\n                features_dict[f'downside_dev_{window}d'] = 0.01\n    \n    # Build feature vector\n    features = []\n    for feat in FEATURE_COLS:\n        val = features_dict.get(feat, 0.0)\n        if np.isnan(val) or np.isinf(val):\n            val = feature_medians.get(feat, 0.0)\n        features.append(val)\n    \n    # Predict market excess return\n    predicted_return = model.predict([features])[0]\n    \n    # Convert to position allocation [0, 2]\n    position = predicted_return * SIGNAL_MULTIPLIER + 1.0\n    position = np.clip(position, MIN_POSITION, MAX_POSITION)\n    \n    # Increment timestep counter\n    inference_state['timestep'] += 1\n    \n    # Debug logging (first few timesteps only)\n    if inference_state['timestep'] <= 3:\n        print(f\"Timestep {inference_state['timestep']}: predicted_return={predicted_return:.6f}, position={position:.4f}\")\n    \n    return float(position)\n\nprint(\"âœ… Predict function defined\")\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:56:50.39916Z","iopub.execute_input":"2025-11-30T18:56:50.399601Z","iopub.status.idle":"2025-11-30T18:56:50.412894Z","shell.execute_reply.started":"2025-11-30T18:56:50.399553Z","shell.execute_reply":"2025-11-30T18:56:50.41188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup Inference Server","metadata":{}},{"cell_type":"code","source":"print(\"=\" * 80)\nprint(\"SETTING UP INFERENCE SERVER\")\nprint(\"=\" * 80)\nprint()\n\n# Create inference server with our predict function\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nprint(\"âœ… Inference server created\")\nprint()\n\n# Start server (competition mode) or run local test\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"ðŸš€ Starting inference server for competition...\")\n    inference_server.serve()\nelse:\n    print(\"ðŸ§ª Running local gateway test...\")\n    inference_server.run_local_gateway((\n        '/kaggle/input/hull-tactical-market-prediction/',\n    ))\n    print(\"âœ… Local test complete\")\n\nprint()\nprint(\"=\" * 80)\nprint(\"INFERENCE SERVER READY!\")\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:57:01.282231Z","iopub.execute_input":"2025-11-30T18:57:01.282595Z","iopub.status.idle":"2025-11-30T18:57:01.452766Z","shell.execute_reply.started":"2025-11-30T18:57:01.282549Z","shell.execute_reply":"2025-11-30T18:57:01.451618Z"}},"outputs":[],"execution_count":null}]}