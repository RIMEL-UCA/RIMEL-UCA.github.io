{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":14348714,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport datetime\n\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom dataclasses import dataclass, asdict\n\nimport polars as pl \nimport numpy as np\nfrom xgboost import XGBRegressor\n\nimport kaggle_evaluation.default_inference_server\n\n# ============ PATH AND CONFIGS ============\n\nDATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n\n# ============ RETURNS TO SIGNAL CONFIGS ============\n\nMIN_SIGNAL: float = 0.0                         \nMAX_SIGNAL: float = 2.0                         \nSIGNAL_MULTIPLIER: float = 400.0                \n\n# ============ XGBOOST CONFIGS ============\n\nMAX_DEPTH: int = 6                                      # 最大深さ\nLEARNING_RATE: float = 0.1                              # 学習率\nN_ESTIMATORS: int = 100                                 # 木の数\nSUBSAMPLE: float = 0.8                                  # サンプリングの割合\nCOLSAMPLE_BYTREE: float = 0.8                           # 木ごとの列サンプル\n\n@dataclass\nclass DatasetOutput:\n    X_train : pl.DataFrame \n    X_test: pl.DataFrame\n    y_train: pl.Series\n    y_test: pl.Series\n    scaler: StandardScaler\n\n@dataclass(frozen=True)\nclass RetToSignalParameters:\n    signal_multiplier: float \n    min_signal : float = MIN_SIGNAL\n    max_signal : float = MAX_SIGNAL\n\nret_signal_params = RetToSignalParameters(\n    signal_multiplier= SIGNAL_MULTIPLIER\n)\n\n# ============ LOAD DATA ============\n\ndef load_trainset() -> pl.DataFrame:\n    \"\"\"\n    Loads and preprocesses the training dataset.\n    \"\"\"\n    return (\n        pl.read_csv(DATA_PATH / \"train.csv\")\n        .rename({'market_forward_excess_returns':'target'})\n        .with_columns(\n            pl.exclude('date_id').cast(pl.Float64, strict=False)\n        )\n        .head(-10)\n    )\n\ndef load_testset() -> pl.DataFrame:\n    \"\"\"\n    Loads and preprocesses the testing dataset.\n    \"\"\"\n    return (\n        pl.read_csv(DATA_PATH / \"test.csv\")\n        .rename({'lagged_forward_returns':'target'})\n        .with_columns(\n            pl.exclude('date_id').cast(pl.Float64, strict=False)\n        )\n    )\n\ndef create_example_dataset(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Creates new features and cleans a DataFrame.\n    \"\"\"\n    vars_to_keep: List[str] = [\n        \"S2\", \"E2\", \"E3\", \"P9\", \"S1\", \"S5\", \"I2\", \"P8\",\n        \"P10\", \"P12\", \"P13\", \"U1\", \"U2\"\n    ]\n    return (\n        df.with_columns(\n            (pl.col(\"I2\") - pl.col(\"I1\")).alias(\"U1\"),\n            (pl.col(\"M11\") / ((pl.col(\"I2\") + pl.col(\"I9\") + pl.col(\"I7\")) / 3)).alias(\"U2\")\n        )\n        .select([\"date_id\", \"target\"] + vars_to_keep)\n        .with_columns([pl.col(col).fill_null(pl.col(col).ewm_mean(com=0.5)) for col in vars_to_keep])\n        .drop_nulls()\n    )\n\ndef join_train_test_dataframes(train: pl.DataFrame, test: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Joins two dataframes by common columns and concatenates them vertically.\n    \"\"\"\n    common_columns: list[str] = [col for col in train.columns if col in test.columns]\n    \n    return pl.concat([train.select(common_columns), test.select(common_columns)], how=\"vertical\")\n\ndef split_dataset(train: pl.DataFrame, test: pl.DataFrame, features: list[str]) -> DatasetOutput:\n    \"\"\"\n    Splits the data into features (X) and target (y), and scales the features.\n    \"\"\"\n    X_train = train.drop(['date_id','target']) \n    y_train = train.get_column('target')\n    X_test = test.drop(['date_id','target']) \n    y_test = test.get_column('target')\n    \n    scaler = StandardScaler() \n    X_train_scaled_np = scaler.fit_transform(X_train)\n    X_train = pl.from_numpy(X_train_scaled_np, schema=features)\n    X_test_scaled_np = scaler.transform(X_test)\n    X_test = pl.from_numpy(X_test_scaled_np, schema=features)\n    \n    return DatasetOutput(\n        X_train = X_train,\n        y_train = y_train, \n        X_test = X_test, \n        y_test = y_test,\n        scaler = scaler\n    )\n\ndef convert_ret_to_signal(ret_arr: np.ndarray, params: RetToSignalParameters) -> np.ndarray:\n    \"\"\"\n    Converts raw model predictions (expected returns) into a trading signal.\n    \"\"\"\n    return np.clip(ret_arr * params.signal_multiplier + 1, params.min_signal, params.max_signal)\n\n# ============ TRAINING THE XGBOOST MODEL ============\n\ntrain: pl.DataFrame = load_trainset()\ntest: pl.DataFrame = load_testset() \n\ndf: pl.DataFrame = join_train_test_dataframes(train, test)\ndf = create_example_dataset(df=df) \ntrain: pl.DataFrame = df.filter(pl.col('date_id').is_in(train.get_column('date_id')))\ntest: pl.DataFrame = df.filter(pl.col('date_id').is_in(test.get_column('date_id')))\n\nFEATURES: list[str] = [col for col in test.columns if col not in ['date_id', 'target']]\n\ndataset: DatasetOutput = split_dataset(train=train, test=test, features=FEATURES) \n\nX_train: pl.DataFrame = dataset.X_train\nX_test: pl.DataFrame = dataset.X_test\ny_train: pl.DataFrame = dataset.y_train\ny_test: pl.DataFrame = dataset.y_test\nscaler: StandardScaler = dataset.scaler \n\n# XGBoostモデルを訓練\nmodel = XGBRegressor(\n    max_depth=MAX_DEPTH,\n    learning_rate=LEARNING_RATE,\n    n_estimators=N_ESTIMATORS,\n    subsample=SUBSAMPLE,\n    colsample_bytree=COLSAMPLE_BYTREE\n)\n\nmodel.fit(X_train.to_numpy(), y_train.to_numpy())\n\n# ============ PREDICTION ============\n\ndef predict(test: pl.DataFrame) -> float:\n    test = test.rename({'lagged_forward_returns':'target'})\n    df: pl.DataFrame = create_example_dataset(test)\n    X_test: pl.DataFrame = df.select(FEATURES)\n    X_test_scaled_np: np.ndarray = scaler.transform(X_test)\n    X_test: pl.DataFrame = pl.from_numpy(X_test_scaled_np, schema=FEATURES)\n    \n    raw_pred: float = model.predict(X_test.to_numpy())[0]\n    return convert_ret_to_signal(raw_pred, ret_signal_params)\n\n# ============ INFERENCE SERVER ============\n\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T17:36:43.035348Z","iopub.execute_input":"2025-11-25T17:36:43.035776Z","iopub.status.idle":"2025-11-25T17:36:44.06846Z","shell.execute_reply.started":"2025-11-25T17:36:43.03575Z","shell.execute_reply":"2025-11-25T17:36:44.067617Z"}},"outputs":[],"execution_count":null}]}